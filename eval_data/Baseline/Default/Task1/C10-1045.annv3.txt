Citance Number: 1 | Reference Article: C10-1045.txt | Citing Article: D12-1046.txt | Citation Marker Offset: ['39'] | Citation Marker: Green and Manning, 2010 | Citation Offset: ['39'] | Citation Text: <S sid ="39" ssid = "13">Joint segmentation and parsing was also investigated for Arabic (Green and Manning, 2010).</S> | Reference Offset: ['7'] | Reference Text: <S sid ="7" ssid = "7">It is well-known that constituency parsing models designed for English often do not generalize easily to other languages and treebanks.1 Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima’an, 2008), and the effect of variable word order (Collins et al., 1999).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 2 | Reference Article: C10-1045.txt | Citing Article: J13-1007.txt | Citation Marker Offset: ['72'] | Citation Marker: Green and Manning 2010 | Citation Offset: ['72'] | Citation Text: <S sid ="72" ssid = "72">Indeed, we have used it to solve the problem of parsing while recovering null elements in both English and Chinese (Cai, Chiang, and Goldberg 2011), and others have used it for the joint segmentation and parsing of Arabic (Green and Manning 2010).</S> | Reference Offset: ['285'] | Reference Text: <S sid ="285" ssid = "78">Despite their simplicity, uni- gram weights have been shown as an effective feature in segmentation models (Dyer, 2009).13 The joint parser/segmenter is compared to a pipeline that uses MADA (v3.0), a state-of-the-art Arabic segmenter, configured to replicate ATB segmentation (Habash and Rambow, 2005).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 3 | Reference Article: C10-1045.txt | Citing Article: J13-1007.txt | Citation Marker Offset: ['148'] | Citation Marker: Green and Manning 2010 | Citation Offset: ['148','149'] | Citation Text: <S sid ="148" ssid = "74">One possible solution to the unobserved word-sequence problem is a pipeline system in which an initial model is in charge of token-segmentation, and the output of the initial model is fed as the input to a second stage parser.</S><S sid ="149" ssid = "75">This is a popular approach in parsing systems for Arabic and Chinese (Jiang, Huang, and Liu 2009; Green and Manning 2010).</S> | Reference Offset: ['285'] | Reference Text: <S sid ="285" ssid = "78">Despite their simplicity, uni- gram weights have been shown as an effective feature in segmentation models (Dyer, 2009).13 The joint parser/segmenter is compared to a pipeline that uses MADA (v3.0), a state-of-the-art Arabic segmenter, configured to replicate ATB segmentation (Habash and Rambow, 2005).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 4 | Reference Article: C10-1045.txt | Citing Article: J13-1007.txt | Citation Marker Offset: ['479'] | Citation Marker: Green and Manning 2010 | Citation Offset: ['479','480'] | Citation Text: <S sid ="479" ssid = "16">This is by now a fairly standard representation for multiple morphological segmentations of Hebrew utterances (Adler 2001; Bar-Haim, Simaâ€™an, and Winter 2005; Adler 2007; Cohen and Smith 2007; Goldberg, Adler, and Elhadad 2008; Goldberg and Tsarfaty 2008; Goldberg and Elhadad 2011).</S><S sid ="480" ssid = "17">It is also used for Arabic (Green and Manning 2010)</S> | Reference Offset: ['7'] | Reference Text: <S sid ="7" ssid = "7">It is well-known that constituency parsing models designed for English often do not generalize easily to other languages and treebanks.1 Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima’an, 2008), and the effect of variable word order (Collins et al., 1999).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 5 | Reference Article: C10-1045.txt | Citing Article: J13-1007.txt | Citation Marker Offset: ['511'] | Citation Marker: 2010 | Citation Offset: ['510','511'] | Citation Text: <S sid ="510" ssid = "47">Lattice parsing was explored in the context of parsing of speech signals by Chappelier et al.</S><S sid ="511" ssid = "48">(1999), Simaâ€™an (1999), and Hall (2005), and in the context of joint word-segmentation and syntactic disambiguation in Cohen and Smith (2007), Goldberg and Tsarfaty (2008), and Green and Manning (2010).</S> | Reference Offset: ['7'] | Reference Text: <S sid ="7" ssid = "7">It is well-known that constituency parsing models designed for English often do not generalize easily to other languages and treebanks.1 Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima’an, 2008), and the effect of variable word order (Collins et al., 1999).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 6 | Reference Article: C10-1045.txt | Citing Article: J13-1007.txt | Citation Marker Offset: ['670'] | Citation Marker: 2010 | Citation Offset: ['670'] | Citation Text: <S sid ="670" ssid = "13">Recently, Green and Manning (2010) report on an extensive set of experiments with several kinds of tree annotations and refinements, and report parsing accuracies of 79% F1 using the Stanford-parser and 82% F1 using the PCFG-LA BerkeleyParser, both when assuming gold word segmentation.</S> | Reference Offset: ['49'] | Reference Text: <S sid ="49" ssid = "23">4 Traditional Arabic linguistic theory treats both of these types as subcategories of noun � &apos;.i . Figure 1: The Stanford parser (Klein and Manning, 2002) is unable to recover the verbal reading of the unvocalized surface form 0 an (Table 1).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 7 | Reference Article: C10-1045.txt | Citing Article: J13-1007.txt | Citation Marker Offset: ['672'] | Citation Marker: Green and Manning 2010 | Citation Offset: ['672'] | Citation Text: <S sid ="672" ssid = "15">The best reported results for parsing Arabic when the gold word segmentation is not known, however, are obtained using a pipeline model in which a tagger and word-segmenter is applied prior to a manually state-split constituency parser, resulting in an F-score of 79% F1 (for sentences of up to 70 words) (Green and Manning 2010).</S> | Reference Offset: ['285'] | Reference Text: <S sid ="285" ssid = "78">Despite their simplicity, uni- gram weights have been shown as an effective feature in segmentation models (Dyer, 2009).13 The joint parser/segmenter is compared to a pipeline that uses MADA (v3.0), a state-of-the-art Arabic segmenter, configured to replicate ATB segmentation (Habash and Rambow, 2005).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 8 | Reference Article: C10-1045.txt | Citing Article: J13-1008.txt | Citation Marker Offset: ['195'] | Citation Marker: Green and Manning 2010 | Citation Offset: ['195'] | Citation Text: <S sid ="195" ssid = "12">As for work on Arabic (MSA), results have been reported on the PATB (Kulick, Gabbard, and Marcus 2006; Diab 2007; Green and Manning 2010)</S> | Reference Offset: ['278'] | Reference Text: <S sid ="278" ssid = "71">Recently, lattices have been used successfully in the parsing of Hebrew (Tsarfaty, 2006; Cohen and Smith, 2007), a Semitic language with similar properties to Arabic.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 9 | Reference Article: C10-1045.txt | Citing Article: J13-1008.txt | Citation Marker Offset: ['196'] | Citation Marker: 2010 | Citation Offset: ['196'] | Citation Text: <S sid ="196" ssid = "13">Recently, Green and Manning (2010) analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short idafa constructions and verbal or equational clauses.</S> | Reference Offset: ['7'] | Reference Text: <S sid ="7" ssid = "7">It is well-known that constituency parsing models designed for English often do not generalize easily to other languages and treebanks.1 Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima’an, 2008), and the effect of variable word order (Collins et al., 1999).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 10 | Reference Article: C10-1045.txt | Citing Article: J13-1008.txt | Citation Marker Offset: ['665'] | Citation Marker: 2010 | Citation Offset: ['665'] | Citation Text: <S sid ="665" ssid = "131">For better comparison with work of others, we adopt the suggestion made by Green and Manning (2010) to evaluate the parsing quality on sentences up to 70 tokens long.</S> | Reference Offset: ['60'] | Reference Text: <S sid ="60" ssid = "34">As a result, Arabic sentences are usually long relative to English, especially after Length English (WSJ) Arabic (ATB) ≤ 20 41.9% 33.7% ≤ 40 92.4% 73.2% ≤ 63 99.7% 92.6% ≤ 70 99.9% 94.9% Table 2: Frequency distribution for sentence lengths in the WSJ (sections 2–23) and the ATB (p1–3).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 11 | Reference Article: C10-1045.txt | Citing Article: J13-1009.txt | Citation Marker Offset: ['190'] | Citation Marker: 2010 | Citation Offset: ['190'] | Citation Text: <S sid ="190" ssid = "29">The Arabic grammar features come from Green and Manning (2010), which contains an ablation study similar to Table 2.</S> | Reference Offset: ['49'] | Reference Text: <S sid ="49" ssid = "23">4 Traditional Arabic linguistic theory treats both of these types as subcategories of noun � &apos;.i . Figure 1: The Stanford parser (Klein and Manning, 2002) is unable to recover the verbal reading of the unvocalized surface form 0 an (Table 1).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 12 | Reference Article: C10-1045.txt | Citing Article: J13-1009.txt | Citation Marker Offset: ['193'] | Citation Marker: 2010 | Citation Offset: ['193'] | Citation Text: <S sid ="193" ssid = "32">For Arabic, we use the head-finding rules from Green and Manning (2010).</S> | Reference Offset: ['49'] | Reference Text: <S sid ="49" ssid = "23">4 Traditional Arabic linguistic theory treats both of these types as subcategories of noun � &apos;.i . Figure 1: The Stanford parser (Klein and Manning, 2002) is unable to recover the verbal reading of the unvocalized surface form 0 an (Table 1).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 13 | Reference Article: C10-1045.txt | Citing Article: J13-1009.txt | Citation Marker Offset: ['316'] | Citation Marker: Green and Manning 2010 | Citation Offset: ['316'] | Citation Text: <S sid ="316" ssid = "36">We previously showed that the â€œKulickâ€ tag set is very effective for basic Arabic parsing (Green and Manning 2010).</S> | Reference Offset: ['7'] | Reference Text: <S sid ="7" ssid = "7">It is well-known that constituency parsing models designed for English often do not generalize easily to other languages and treebanks.1 Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima’an, 2008), and the effect of variable word order (Collins et al., 1999).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 14 | Reference Article: C10-1045.txt | Citing Article: J13-1009.txt | Citation Marker Offset: ['397'] | Citation Marker: Green and Manning 2010 | Citation Offset: ['397'] | Citation Text: <S sid ="397" ssid = "13">We previously showed that segmentation errors decrease Arabic parsing accuracy by about 2.0% F1 (Green and Manning 2010).</S> | Reference Offset: ['6'] | Reference Text: <S sid ="6" ssid = "6">Finally, we show that in application settings, the absence of gold segmentation lowers parsing performance by 2–5% F1.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 15 | Reference Article: C10-1045.txt | Citing Article: J13-1009.txt | Citation Marker Offset: ['406'] | Citation Marker: Green and Manning 2010 | Citation Offset: ['406'] | Citation Text: <S sid ="406" ssid = "22">We previously showed optimal Berkeley parser (Petrov et al. 2006) pa- rameterizations for both the Arabic (Green and Manning 2010) and French (Green et al. 2011) data sets</S> | Reference Offset: ['150'] | Reference Text: <S sid ="150" ssid = "17">We compare the manually annotated grammar, which we incorporate into the Stanford parser, to both the Berkeley (Petrov et al., 2006) and Bikel (Bikel, 2004) parsers.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 17 | Reference Article: C10-1045.txt | Citing Article: P11-1159.txt | Citation Marker Offset: ['109'] | Citation Marker: 2010 | Citation Offset: ['109'] | Citation Text: <S sid ="109" ssid = "36">Recently, Green and Manning (2010) analyzed the PATB for annotation consistency</S> | Reference Offset: ['120'] | Reference Text: <S sid ="120" ssid = "8">We also add an annotation for one-level iDafa (oneLevelIdafa) constructs since they make up more than 75% of the iDafa NPs in the ATB (Gabbard and Kulick, 2008).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 18 | Reference Article: C10-1045.txt | Citing Article: P11-2037.txt | Citation Marker Offset: ['34'] | Citation Marker: Green and Manning, 2010 | Citation Offset: ['34'] | Citation Text: <S sid ="34" ssid = "12">We allow the parser to produce empty elements by means of lattice-parsing (Chappelier et al., 1999), a general processing community (Hall, 2005; Chappelier et al., 1999), and was recently applied to the task of joint clitic-segmentation and syntactic-parsing in Hebrew (Goldberg and Tsarfaty, 2008; Goldberg and Elhadad, 2011) and Arabic (Green and Manning, 2010).</S> | Reference Offset: ['7'] | Reference Text: <S sid ="7" ssid = "7">It is well-known that constituency parsing models designed for English often do not generalize easily to other languages and treebanks.1 Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima’an, 2008), and the effect of variable word order (Collins et al., 1999).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 19 | Reference Article: C10-1045.txt | Citing Article: P11-2122.txt | Citation Marker Offset: ['7'] | Citation Marker: Green and Manning, 2010 | Citation Offset: ['7'] | Citation Text: <S sid ="7" ssid = "7">Recent work has therefore focused on the importance of detecting errors in the treebank (Green and Manning, 2010)</S> | Reference Offset: ['236'] | Reference Text: <S sid ="236" ssid = "29">We report micro-averaged (whole corpus) and macro-averaged (per sentence) scores along add a constraint on the removal of punctuation, which has a single tag (PUNC) in the ATB.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 20 | Reference Article: C10-1045.txt | Citing Article: P11-2122.txt | Citation Marker Offset: ['73'] | Citation Marker: 2010 | Citation Offset: ['73'] | Citation Text: <S sid ="73" ssid = "1">Green and Manning (2010) discuss annotation consistency in the Penn Arabic Treebank (ATB)</S> | Reference Offset: ['3'] | Reference Text: <S sid ="3" ssid = "3">Second, we show that although the Penn Arabic Treebank is similar to other tree- banks in gross statistical terms, annotation consistency remains problematic.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 21 | Reference Article: C10-1045.txt | Citing Article: P11-2122.txt | Citation Marker Offset: ['109'] | Citation Marker: 2010 | Citation Offset: ['109'] | Citation Text: <S sid ="109" ssid = "37">Measuring recall is tricky, even using the errors identified in Green and Manning (2010) as â€œgoldâ€ errors.</S> | Reference Offset: ['49'] | Reference Text: <S sid ="49" ssid = "23">4 Traditional Arabic linguistic theory treats both of these types as subcategories of noun � &apos;.i . Figure 1: The Stanford parser (Klein and Manning, 2002) is unable to recover the verbal reading of the unvocalized surface form 0 an (Table 1).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 22 | Reference Article: C10-1045.txt | Citing Article: P11-2124.txt | Citation Marker Offset: ['18'] | Citation Marker: 2010 | Citation Offset: ['18'] | Citation Text: <S sid ="18" ssid = "18">Recently, Green and Manning (2010) demonstrated the effectiveness of lattice-parsing for parsing Arabic.</S> | Reference Offset: ['7'] | Reference Text: <S sid ="7" ssid = "7">It is well-known that constituency parsing models designed for English often do not generalize easily to other languages and treebanks.1 Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima’an, 2008), and the effect of variable word order (Collins et al., 1999).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 23 | Reference Article: C10-1045.txt | Citing Article: P12-1016.txt | Citation Marker Offset: ['196'] | Citation Marker: Green and Manning, 2010 | Citation Offset: ['196'] | Citation Text: <S sid ="196" ssid = "23">The data was pre-processed with packages from the Stanford Arabic parser (Green and Manning, 2010).</S> | Reference Offset: ['49'] | Reference Text: <S sid ="49" ssid = "23">4 Traditional Arabic linguistic theory treats both of these types as subcategories of noun � &apos;.i . Figure 1: The Stanford parser (Klein and Manning, 2002) is unable to recover the verbal reading of the unvocalized surface form 0 an (Table 1).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 24 | Reference Article: C10-1045.txt | Citing Article: P12-2002.txt | Citation Marker Offset: ['12'] | Citation Marker: Green and Manning, 2010 | Citation Offset: ['12'] | Citation Text: <S sid ="12" ssid = "12">One can either select a segmentation path prior to parsing, or, as has been recently argued, one can let the parser pick a segmentation jointly with decoding (Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008; Green and Manning, 2010).</S> | Reference Offset: ['278'] | Reference Text: <S sid ="278" ssid = "71">Recently, lattices have been used successfully in the parsing of Hebrew (Tsarfaty, 2006; Cohen and Smith, 2007), a Semitic language with similar properties to Arabic.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 25 | Reference Article: C10-1045.txt | Citing Article: P12-2002.txt | Citation Marker Offset: ['34'] | Citation Marker: 2010 | Citation Offset: ['34','35'] | Citation Text: <S sid ="34" ssid = "12">2 The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008).</S><S sid ="35" ssid = "13">Examples for similar phenomena in Arabic may be found in Green and Manning (2010).</S> | Reference Offset: ['7'] | Reference Text: <S sid ="7" ssid = "7">It is well-known that constituency parsing models designed for English often do not generalize easily to other languages and treebanks.1 Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima’an, 2008), and the effect of variable word order (Collins et al., 1999).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 26 | Reference Article: C10-1045.txt | Citing Article: P12-2002.txt | Citation Marker Offset: ['39'] | Citation Marker: Green and Manning, 2010 | Citation Offset: ['38','39'] | Citation Text: <S sid ="38" ssid = "16">In practice, a statistical component is required to decide on the correct morphological segmentation, that is, to pick out the correct path through the lattice.</S><S sid ="39" ssid = "17">This may be done based on linear local context (Adler and Elhadad, 2006; Shacham and Wintner, 2007; Bar-haim et al., 2008; Habash and Rambow, 2005), or jointly with parsing (Tsarfaty, 2006; Goldberg and Tsarfaty, 2008; Green and Manning, 2010).</S> | Reference Offset: ['7'] | Reference Text: <S sid ="7" ssid = "7">It is well-known that constituency parsing models designed for English often do not generalize easily to other languages and treebanks.1 Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima’an, 2008), and the effect of variable word order (Collins et al., 1999).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 27 | Reference Article: C10-1045.txt | Citing Article: W13-4904.txt | Citation Marker Offset: ['115'] | Citation Marker: 2010 | Citation Offset: ['115'] | Citation Text: <S sid ="115" ssid = "46">Following Green and Manning (2010) and others, sentences headed by X nodes are deleted</S> | Reference Offset: ['60'] | Reference Text: <S sid ="60" ssid = "34">As a result, Arabic sentences are usually long relative to English, especially after Length English (WSJ) Arabic (ATB) ≤ 20 41.9% 33.7% ≤ 40 92.4% 73.2% ≤ 63 99.7% 92.6% ≤ 70 99.9% 94.9% Table 2: Frequency distribution for sentence lengths in the WSJ (sections 2–23) and the ATB (p1–3).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 28 | Reference Article: C10-1045.txt | Citing Article: W13-4904.txt | Citation Marker Offset: ['234'] | Citation Marker: 2010 | Citation Offset: ['234'] | Citation Text: <S sid ="234" ssid = "86">Green and Manning (2010) obtain the opposite result in their Arabic parsing experiments, with the lattice parser underperforming the pipeline system by over 3 points (76.01 F1 vs 79.17 F1).</S> | Reference Offset: ['60'] | Reference Text: <S sid ="60" ssid = "34">As a result, Arabic sentences are usually long relative to English, especially after Length English (WSJ) Arabic (ATB) ≤ 20 41.9% 33.7% ≤ 40 92.4% 73.2% ≤ 63 99.7% 92.6% ≤ 70 99.9% 94.9% Table 2: Frequency distribution for sentence lengths in the WSJ (sections 2–23) and the ATB (p1–3).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 29 | Reference Article: C10-1045.txt | Citing Article: W13-4904.txt | Citation Marker Offset: ['244'] | Citation Marker: 2010 | Citation Offset: ['244'] | Citation Text: <S sid ="244" ssid = "96">Green and Manning (2010) find that using automatic tokenization provided by MADA (Habash et al., 2009) instead of gold tokenization results in a 1.92% F score drop in their constituent parsing work.</S> | Reference Offset: ['285'] | Reference Text: <S sid ="285" ssid = "78">Despite their simplicity, uni- gram weights have been shown as an effective feature in segmentation models (Dyer, 2009).13 The joint parser/segmenter is compared to a pipeline that uses MADA (v3.0), a state-of-the-art Arabic segmenter, configured to replicate ATB segmentation (Habash and Rambow, 2005).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 31 | Reference Article: C10-1045.txt | Citing Article: W13-4917.txt | Citation Marker Offset: ['260'] | Citation Marker: 2010 | Citation Offset: ['260'] | Citation Text: <S sid ="260" ssid = "60">The Stanford Arabic Phrase Structure Treebank In order to stay compatible with the state of the art, we provide the constituency data set with most of the pre-processing steps of Green and Manning (2010)</S> | Reference Offset: ['49'] | Reference Text: <S sid ="49" ssid = "23">4 Traditional Arabic linguistic theory treats both of these types as subcategories of noun � &apos;.i . Figure 1: The Stanford parser (Klein and Manning, 2002) is unable to recover the verbal reading of the unvocalized surface form 0 an (Table 1).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 32 | Reference Article: C10-1045.txt | Citing Article: W13-4917.txt | Citation Marker Offset: ['262'] | Citation Marker: 2010 | Citation Offset: ['262'] | Citation Text: <S sid ="262" ssid = "62">We finally remove all traces, but, unlike Green and Manning (2010), we keep all function tags.</S> | Reference Offset: ['154'] | Reference Text: <S sid ="154" ssid = "21">At the phrasal level, we remove all function tags and traces.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 33 | Reference Article: C10-1045.txt | Citing Article: W13-4917.txt | Citation Marker Offset: ['218'] | Citation Marker: Green and Manning, 2010 | Citation Offset: ['218'] | Citation Text: <S sid ="218" ssid = "18">Data Sets The Arabic data set contains two tree- banks derived from the LDC Penn Arabic Treebanks (PATB) (Maamouri et al., 2004b):11 the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), a dependency treebank, and the Stanford version of the PATB (Green and Manning, 2010)</S> | Reference Offset: ['285'] | Reference Text: <S sid ="285" ssid = "78">Despite their simplicity, uni- gram weights have been shown as an effective feature in segmentation models (Dyer, 2009).13 The joint parser/segmenter is compared to a pipeline that uses MADA (v3.0), a state-of-the-art Arabic segmenter, configured to replicate ATB segmentation (Habash and Rambow, 2005).</S> | Discourse Facet: BLANK | Annotator: Predictions

