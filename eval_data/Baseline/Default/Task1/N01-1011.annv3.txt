Citance Number: 1 | Reference Article: N01-1011.xml | Citing Article: W02-0812.xml | Citation Marker Offset: ['131'] | Citation Marker: Pedersen, 2001a | Citation Offset: ['131','132','133'] | Citation Text: <S sid ="131" ssid = "33">The frustration with models that lack an intuitive interpretation led to the development of decision trees based on bigram features (Pedersen, 2001a).</S><S sid ="132" ssid = "34">This is quite similar to the bagged decision trees of bigrams (B) presented here, except that the ear­lier work learns a single decision tree where training examples are represented by the top 100 ranked bi-grams, according to the log–likelihood ratio.</S><S sid ="133" ssid = "35">This earlier approach was evaluated on the SENSEVAL­1 data and achieved an overall accuracy of 64%, whereas the bagged decision tree presented here achieves an accuracy of 68% on that data.</S> | Reference Offset: ['146'] | Reference Text: <S sid ="146" ssid = "14">Since a bigram feature can only appear once in the decision tree, the number of inter- Table 2: Decision Tree and Stump Characteristics power divergence dice coeÆcient (1) (2) (3) (4) (5) (6) (7) word-pos stump node leaf/total features stump node leaf/total features accident-n by accident 8/15 101 by accident 12/23 112 behaviour-n best behaviour 2/3 100 best behaviour 2/3 104 bet-n betting shop 20/39 50 betting shop 20/39 50 excess-n in excess 13/25 104 in excess 11/21 102 oat-n the oat 7/13 13 the oat 7/13 13 giant-n the giants 16/31 103 the giants 14/27 78 knee-n knee injury 23/45 102 knee injury 20/39 104 onion-n in the 1/1 7 in the 1/1 7 promise-n promise of 95/189 100 a promising 49/97 107 sack-n the sack 5/9 31 the sack 5/9 31 scrap-n scrap of 7/13 8 scrap of 7/13 8 shirt-n shirt and 38/75 101 shirt and 55/109 101 amaze-v amazed at 11/21 102 amazed at 11/21 102 bet-v i bet 4/7 10 i bet 4/7 10 bother-v be bothered 19/37 101 be bothered 20/39 106 bury-v buried in 28/55 103 buried in 32/63 103 calculate-v calculated to 5/9 103 calculated to 5/9 103 consume-v on the 4/7 20 on the 4/7 20 derive-v derived from 10/19 104 derived from 10/19 104 oat-v oated on 24/47 80 oated on 24/47 80 invade-v to invade 55/109 107 to invade 66/127 108 promise-v promise to 3/5 100 promise you 5/9 106 sack-v return to 1/1 91 return to 1/1 91 scrap-v of the 1/1 7 of the 1/1 7 seize-v to seize 26/51 104 to seize 57/113 104 brilliant-a a brilliant 26/51 101 a brilliant 42/83 103 oating-a in the 7/13 10 in the 7/13 10 generous-a a generous 57/113 103 a generous 56/111 102 giant-a the giant 2/3 102 a giant 1/1 101 modest-a a modest 14/27 101 a modest 10/19 105 slight-a the slightest 2/3 105 the slightest 2/3 105 wooden-a wooden spoon 2/3 104 wooden spoon 2/3 101 band-p band of 14/27 100 the band 21/41 117 bitter-p a bitter 22/43 54 a bitter 22/43 54 sanction-p south africa 12/23 52 south africa 12/23 52 shake-p his head 90/179 100 his head 81/161 105 nal nodes represents the number of bigram features selected by the decision tree learner.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 2 | Reference Article: N01-1011.xml | Citing Article: W04-0813.xml | Citation Marker Offset: ['43'] | Citation Marker: Pedersen, 2001 | Citation Offset: ['43'] | Citation Text: <S sid ="43" ssid = "23">We also obtain salient bigrams in the con­text, with the methods and the software de­scribed in (Pedersen, 2001).</S> | Reference Offset: ['27'] | Reference Text: <S sid ="27" ssid = "1">We have developed an approach to word sense disambiguation that represents text entirely in terms of the occurrence of bigrams, which we de?ne to be two cat :cat totals big n 11 = 10 n 12 = 20 n 1+ = 30 :big n 21 = 40 n 22 = 930 n 2+ = 970 totals n +1 =50 n +2 =950 n ++ =1000 Figure 1: Representation of Bigram Counts consecutive words that occur in a text.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 3 | Reference Article: N01-1011.xml | Citing Article: W02-1011.xml | Citation Marker Offset: ['136'] | Citation Marker: 2001 | Citation Offset: ['136'] | Citation Text: <S sid ="136" ssid = "45">in fact, Pedersen (2001) found that bigrams alone can be e.ective features for word sense disambiguation.</S> | Reference Offset: ['169'] | Reference Text: <S sid ="169" ssid = "1">Bigrams have been used as features for word sense disambiguation, particularly in the form of collocations where the ambiguous word is one component of the bigram (e.g., (Bruce and Wiebe, 1994), (Ng and Lee, 1996), (Yarowsky, 1995)).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 4 | Reference Article: N01-1011.xml | Citing Article: N03-3004.xml | Citation Marker Offset: ['49'] | Citation Marker: Pedersen, 2001 | Citation Offset: ['49'] | Citation Text: <S sid ="49" ssid = "9">Bigrams have recently been shown to be very successful features in supervised word sense disambiguation (Peder­sen, 2001).</S> | Reference Offset: ['169'] | Reference Text: <S sid ="169" ssid = "1">Bigrams have been used as features for word sense disambiguation, particularly in the form of collocations where the ambiguous word is one component of the bigram (e.g., (Bruce and Wiebe, 1994), (Ng and Lee, 1996), (Yarowsky, 1995)).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 7 | Reference Article: N01-1011.xml | Citing Article: J02-2003.xml | Citation Marker Offset: ['148'] | Citation Marker: 2001 | Citation Offset: ['148'] | Citation Text: <S sid ="148" ssid = "54">In addition, Pedersen (2001) questions whether one statistic should be preferred over the other for the bigram acquisition task and cites Cressie and Read (1984), who argue that there are some cases where the Pearson statistic is more reliable than the log-likelihood statistic.</S> | Reference Offset: ['40'] | Reference Text: <S sid ="40" ssid = "14">However, (Cressie and Read, 1984) suggest that there are cases where Pearson&apos;s statistic is more reliable than the likelihood ratio and that one test should not always be preferred over the other.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 8 | Reference Article: N01-1011.xml | Citing Article: W08-0611.xml | Citation Marker Offset: ['103'] | Citation Marker: 2001 | Citation Offset: ['103'] | Citation Text: <S sid ="103" ssid = "17">• Salient bigrams: Salient bigrams within the abstract with high log-likelihood scores, as described by Pedersen (2001).</S> | Reference Offset: ['59'] | Reference Text: <S sid ="59" ssid = "33">The Dice CoeÆcient overcomes this limitation, and can be de?ned as follows: Dice(w 1 ; w 2 ) = 2 ? n 11 n +1 + n 1+ When n 11 = n 1+ = n +1 the value of Dice(w 1 ; w 2 ) will be 1 for all values n 11 . When the value of n. 11 is less than either of the marginal totals (the more typical case) the rankings produced by the Dice Co- eÆcient are similar to those of Mutual Information.</S> | Discourse Facet: BLANK | Annotator: Predictions

