Citance Number: 1 | Reference Article: N09-1001 | Citing Article: N09_csl2013 | Citation Marker Offset: '147' | Citation Marker: 2009.0 | Citation Offset: '146', '147' | Citation Text: <S sid ="146" ssid = "86">The work closest to ours is the subjectivity word sense disambiguation method proposed in Akkaya et al.</S><S sid ="147" ssid = "87">(2009), where on a set of 83 English words, an accuracy of 88% was observed; and the method proposed in Su and Markert (2009), where an accuracy of 84% was obtained on another dataset of 298 words.</S> | Reference Offset: ['205'] | Reference Text: <S sid ="205" ssid = "47">In our previous work (Su and Markert, 2008), we report 76.9% as the best accuracy on the same Micro Table 5: Accuracy with different sizes of unlabeled data from WordNet relation Re lati on # unl ab ele d da ta Ac cu ra cy {∅ } 0 75 .3 % {si milar to } 41 8 79 .1 % {si milar to, ant on ym } 51 4 79 .5 % {si milarto, antonym, direct-hypernym, direct hy po ny m } 2, 72 1 84 .4 % {si milarto, antonym, direct-hypernym, direct hy po ny m, also se e, ext en ded ant on ym } 3, 00 4 84 .4 % {si milarto, antonym, direct-hypernym, direct hy po ny m, al so se e, ex te nd ed an to ny m, d eri ved fr o m , at tri bu te , d o m ai n, d o m ain m e m be r} 3, 22 0 84 .6 % 89 Option1 87 Option2.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 2 | Reference Article: N09-1001 | Citing Article: N09_qwn | Citation Marker Offset: '22' | Citation Marker: Su and Markert, 2009 | Citation Offset: '22' | Citation Text: <S sid ="22" ssid = "22">Although it can be used in its current form for data-driven Sentiment Analysis (Pang et al., 2002; Pang and Lee, 2004; Kim and Hovy, 2004; Popescu and Etzioni, 2005; Su and Markert, 2009; DanescuNiculescu- Mizil et al., 2009), or for lexical sentiment analysis tasks (Strapparava and Mihalcea, 2007; Su and Markert, 2009), it could also be used as a training set for supervised classifiers that would subsequently be applied for the improvement of Q-WordNet.</S> | Reference Offset: ['27'] | Reference Text: <S sid ="27" ssid = "1">There has been a large and diverse body of research in opinion mining, with most research at the text (Pang et al., 2002; Pang and Lee, 2004; Popescu and Etzioni, 2005; Ounis et al., 2006), sentence (Kim and Hovy, 2005; Kudo and Matsumoto, 2004; Riloff et al., 2003; Yu and Hatzivassiloglou, 2003) or word (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Kim and Hovy, 2004; Takamura et al., 2005; Andreevskaia and Bergler, 2006; Kaji and Kitsuregawa, 2007) level.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 3 | Reference Article: N09-1001 | Citing Article: N09_qwn | Citation Marker Offset: '22' | Citation Marker: Su and Markert, 2009 | Citation Offset: '22' | Citation Text: <S sid ="22" ssid = "22">Although it can be used in its current form for data-driven Sentiment Analysis (Pang et al., 2002; Pang and Lee, 2004; Kim and Hovy, 2004; Popescu and Etzioni, 2005; Su and Markert, 2009; DanescuNiculescu- Mizil et al., 2009), or for lexical sentiment analysis tasks (Strapparava and Mihalcea, 2007; Su and Markert, 2009), it could also be used as a training set for supervised classifiers that would subsequently be applied for the improvement of Q-WordNet.</S> | Reference Offset: ['27'] | Reference Text: <S sid ="27" ssid = "1">There has been a large and diverse body of research in opinion mining, with most research at the text (Pang et al., 2002; Pang and Lee, 2004; Popescu and Etzioni, 2005; Ounis et al., 2006), sentence (Kim and Hovy, 2005; Kudo and Matsumoto, 2004; Riloff et al., 2003; Yu and Hatzivassiloglou, 2003) or word (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Kim and Hovy, 2004; Takamura et al., 2005; Andreevskaia and Bergler, 2006; Kaji and Kitsuregawa, 2007) level.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 4 | Reference Article: N09-1001 | Citing Article: N09prod | Citation Marker Offset: '35' | Citation Marker: 5.0 | Citation Offset: '35' | Citation Text: <S sid ="35" ssid = "5">Pang[4] and Su[5] both optimized their multi-classification results using the Mincut model.</S> | Reference Offset: ['62'] | Reference Text: <S sid ="62" ssid = "15">W (S, T ) = ) u∈S,v∈T w(u, v)The formulation of our semi supervised Mincut for sense subjectivity classification involves the follow Globally optimal minimum cuts can be found in polynomial time and near-linear running time in practice, using the maximum flow algorithm (Pang and Lee, 2004; Cormen et al., 2002).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 5 | Reference Article: N09-1001 | Citing Article: N09prod | Citation Marker Offset: '121' | Citation Marker: 5.0 | Citation Offset: '121' | Citation Text: <S sid ="121" ssid = "25">Inspired by work of Pang[4] and Su[5], we also use Minimum cut (Mincut) model to optimize the Two-stage SVM result.</S> | Reference Offset: ['205'] | Reference Text: <S sid ="205" ssid = "47">In our previous work (Su and Markert, 2008), we report 76.9% as the best accuracy on the same Micro Table 5: Accuracy with different sizes of unlabeled data from WordNet relation Re lati on # unl ab ele d da ta Ac cu ra cy {∅ } 0 75 .3 % {si milar to } 41 8 79 .1 % {si milar to, ant on ym } 51 4 79 .5 % {si milarto, antonym, direct-hypernym, direct hy po ny m } 2, 72 1 84 .4 % {si milarto, antonym, direct-hypernym, direct hy po ny m, also se e, ext en ded ant on ym } 3, 00 4 84 .4 % {si milarto, antonym, direct-hypernym, direct hy po ny m, al so se e, ex te nd ed an to ny m, d eri ved fr o m , at tri bu te , d o m ai n, d o m ain m e m be r} 3, 22 0 84 .6 % 89 Option1 87 Option2.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 6 | Reference Article: N09-1001 | Citing Article: N15-1071 | Citation Marker Offset: '147' | Citation Marker: 2009.0 | Citation Offset: '147' | Citation Text: <S sid ="147" ssid = "36">The MWE productions seem to overlap with well- known linguistic phenomena  consider Fahrni and Klenner (2008) and their claim that most adjectives have a polarity that is dependent on the target they modify instead of having a prior polarity that holds independently of the target, or the observation of Su and Markert (2009) that sentiment should be dependent on word senses instead of word forms (which would capture a large number of examples within the expression strengthening category).</S> | Reference Offset: ['14'] | Reference Text: <S sid ="14" ssid = "14">A typical subjectivity-ambiguous word, i.e. a word that has at least one subjective and at least one objective sense, is positive, as shown by the two example senses given below.1 (1) positive, electropositive—having a positive electric charge;“protons are positive” (objective) (2) plus, positive—involving advantage or good; “a plus (or positive) factor” (subjective) We concentrate on this latter problem by automatically creating lists of subjective senses, instead of subjective words, via adding subjectivity labels for senses to electronic lexica, using the example of WordNet.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 7 | Reference Article: N09-1001 | Citing Article: P101167 | Citation Marker Offset: '146' | Citation Marker: 2009.0 | Citation Offset: '146' | Citation Text: <S sid ="146" ssid = "96">Su and Markert (2009) propose a semi-supervised minimum cut framework to label word sense entries in WordNet with subjectivity information.</S> | Reference Offset: ['20'] | Reference Text: <S sid ="20" ssid = "20">Qc 2009 Association for Computational Linguistics We propose a semi-supervised approach based on minimum cut in a lexical relation graph to assign subjectivity (subjective/objective) labels to word senses.2 Our algorithm outperforms supervised minimum cuts and standard supervised, non-graph classification algorithms (like SVM), reducing the error rate by up to 40%.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 8 | Reference Article: N09-1001 | Citing Article: P1018 | Citation Marker Offset: '10' | Citation Marker: 2009.0 | Citation Offset: '10' | Citation Text: <S sid ="10" ssid = "10">In more recent work it has been argued that the classification of subjectivity vs. objectivity needs to be done independently from the polarity identification (Gyamfi et al., 2009; Su and Markert, 2009).</S> | Reference Offset: ['205'] | Reference Text: <S sid ="205" ssid = "47">In our previous work (Su and Markert, 2008), we report 76.9% as the best accuracy on the same Micro Table 5: Accuracy with different sizes of unlabeled data from WordNet relation Re lati on # unl ab ele d da ta Ac cu ra cy {∅ } 0 75 .3 % {si milar to } 41 8 79 .1 % {si milar to, ant on ym } 51 4 79 .5 % {si milarto, antonym, direct-hypernym, direct hy po ny m } 2, 72 1 84 .4 % {si milarto, antonym, direct-hypernym, direct hy po ny m, also se e, ext en ded ant on ym } 3, 00 4 84 .4 % {si milarto, antonym, direct-hypernym, direct hy po ny m, al so se e, ex te nd ed an to ny m, d eri ved fr o m , at tri bu te , d o m ai n, d o m ain m e m be r} 3, 22 0 84 .6 % 89 Option1 87 Option2.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 9 | Reference Article: N09-1001 | Citing Article: P1018 | Citation Marker Offset: '180' | Citation Marker: 2009.0 | Citation Offset: '180' | Citation Text: <S sid ="180" ssid = "2">For example, Su and Markert (2009) make use of both Wordnet definitions and Wordnet relations and achieve an accuracy of 84.6% on all parts-of-speech.</S> | Reference Offset: ['205'] | Reference Text: <S sid ="205" ssid = "47">In our previous work (Su and Markert, 2008), we report 76.9% as the best accuracy on the same Micro Table 5: Accuracy with different sizes of unlabeled data from WordNet relation Re lati on # unl ab ele d da ta Ac cu ra cy {∅ } 0 75 .3 % {si milar to } 41 8 79 .1 % {si milar to, ant on ym } 51 4 79 .5 % {si milarto, antonym, direct-hypernym, direct hy po ny m } 2, 72 1 84 .4 % {si milarto, antonym, direct-hypernym, direct hy po ny m, also se e, ext en ded ant on ym } 3, 00 4 84 .4 % {si milarto, antonym, direct-hypernym, direct hy po ny m, al so se e, ex te nd ed an to ny m, d eri ved fr o m , at tri bu te , d o m ai n, d o m ain m e m be r} 3, 22 0 84 .6 % 89 Option1 87 Option2.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 10 | Reference Article: N09-1001 | Citing Article: PEAAI_n09 | Citation Marker Offset: '70' | Citation Marker: 2009.0 | Citation Offset: '70' | Citation Text: <S sid ="70" ssid = "30">Semi-supervised techniques on text mining were applied by Fangzhong and Markert (2009).</S> | Reference Offset: ['20'] | Reference Text: <S sid ="20" ssid = "20">Qc 2009 Association for Computational Linguistics We propose a semi-supervised approach based on minimum cut in a lexical relation graph to assign subjectivity (subjective/objective) labels to word senses.2 Our algorithm outperforms supervised minimum cuts and standard supervised, non-graph classification algorithms (like SVM), reducing the error rate by up to 40%.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 11 | Reference Article: N09-1001 | Citing Article: Pproc2014_n09 | Citation Marker Offset: '33' | Citation Marker: 2009.0 | Citation Offset: '33' | Citation Text: <S sid ="33" ssid = "4">The antonymous classes of each are -effect events: destroying the building has a negative effect on the building; demand decreasing has a negative effect on demand; and killing Bill has a negative effect on Bill.4 While sentiment (Esuli and Sebastiani, 2006; Wilson et al., 2005; Su and Markert, 2009) and connotation lexicons (Feng et al., 2011; Kang et al., 2014) are related, sentiment, connotation, and +/-effects are not the same; a single event may have different sentiment and +/-effect polarities, for example.</S> | Reference Offset: ['29'] | Reference Text: <S sid ="29" ssid = "3">Graph-based algorithms for classification into subjective/objective or positive/negative language units have been mostly used at the sentence and document level (Pang and Lee, 2004; Agarwal and Bhattacharyya, 2005; Thomas et al., 2006), instead of aiming at dictionary annotation as we do.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 12 | Reference Article: N09-1001 | Citing Article: Pproc2014_n09 | Citation Marker Offset: '70' | Citation Marker: 2009.0 | Citation Offset: '70' | Citation Text: <S sid ="70" ssid = "16">Su and Markert (2009) adopt a semi-supervised mincut method to recognize the subjectivity of word senses.</S> | Reference Offset: ['20'] | Reference Text: <S sid ="20" ssid = "20">Qc 2009 Association for Computational Linguistics We propose a semi-supervised approach based on minimum cut in a lexical relation graph to assign subjectivity (subjective/objective) labels to word senses.2 Our algorithm outperforms supervised minimum cuts and standard supervised, non-graph classification algorithms (like SVM), reducing the error rate by up to 40%.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 13 | Reference Article: N09-1001 | Citing Article: W11-0311 | Citation Marker Offset: '231' | Citation Marker: 2009.0 | Citation Offset: '231' | Citation Text: <S sid ="231" ssid = "1">One related line of research is to automatically assign subjectivity and/or polarity labels to word senses in a dictionary (Valitutti et al., 2004; An- dreevskaia and Bergler, 2006; Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2007; Su and Markert, 2009).</S> | Reference Offset: ['27'] | Reference Text: <S sid ="27" ssid = "1">There has been a large and diverse body of research in opinion mining, with most research at the text (Pang et al., 2002; Pang and Lee, 2004; Popescu and Etzioni, 2005; Ounis et al., 2006), sentence (Kim and Hovy, 2005; Kudo and Matsumoto, 2004; Riloff et al., 2003; Yu and Hatzivassiloglou, 2003) or word (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Kim and Hovy, 2004; Takamura et al., 2005; Andreevskaia and Bergler, 2006; Kaji and Kitsuregawa, 2007) level.</S> | Discourse Facet: BLANK | Annotator: Predictions

