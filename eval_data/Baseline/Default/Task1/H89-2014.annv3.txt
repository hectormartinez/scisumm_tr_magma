Citance Number: 1 | Reference Article: H89-2014.xml | Citing Article: W93-0111.xml | Citation Marker Offset: ['178'] | Citation Marker: Kupiec, 1989 | Citation Offset: ['178'] | Citation Text: <S sid ="178" ssid = "178">This approach is similar in spirit to the iterative computational approaches of the Hidden Markov Models (Kupiec, 1989</S> | Reference Offset: ['23'] | Reference Text: <S sid ="23" ssid = "23">An alternative approach taken by Jelinek, (Jelinek, 1985) is to view the training problem in terms of a &quot;hidden&quot; Markov model: that is, only the words of the training text are available, their corresponding categories are not known.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 2 | Reference Article: H89-2014.xml | Citing Article: A92-1018.xml | Citation Marker Offset: ['47'] | Citation Marker: Kupiec, 1989a | Citation Offset: ['47'] | Citation Text: <S sid ="47" ssid = "47">In [Kupiec, 1989a], networks are used to selectively augment the context in a basic first- order model, rather than using uniformly second-order dependencies.</S> | Reference Offset: ['4'] | Reference Text: <S sid ="4" ssid = "4">State chains are used to model selective higher-order conditioning in the model, which obviates the proliferation of parameters attendant in uniformly higher-order models.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 3 | Reference Article: H89-2014.xml | Citing Article: A92-1018.xml | Citation Marker Offset: ['108'] | Citation Marker: Kupiec, 1989a | Citation Offset: ['108'] | Citation Text: <S sid ="108" ssid = "108">adequate training requires processing from tens of thousands to hundreds of thousands of tokens [Kupiec, 1989a].</S> | Reference Offset: ['23'] | Reference Text: <S sid ="23" ssid = "23">An alternative approach taken by Jelinek, (Jelinek, 1985) is to view the training problem in terms of a &quot;hidden&quot; Markov model: that is, only the words of the training text are available, their corresponding categories are not known.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 4 | Reference Article: H89-2014.xml | Citing Article: J93-2006.xml | Citation Marker Offset: ['41'] | Citation Marker: Kupiec 1989 | Citation Offset: ['40','41'] | Citation Text: <S sid ="40" ssid = "40">We report in Section 2 on our experiments on the assignment of part of speech to words in text.</S><S sid ="41" ssid = "41">The effectiveness of such models is well known (DeRose 1988; Church 1988; Kupiec 1989; Jelinek 1985)</S> | Reference Offset: ['23'] | Reference Text: <S sid ="23" ssid = "23">An alternative approach taken by Jelinek, (Jelinek, 1985) is to view the training problem in terms of a &quot;hidden&quot; Markov model: that is, only the words of the training text are available, their corresponding categories are not known.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 5 | Reference Article: H89-2014.xml | Citing Article: H91-1046.xml | Citation Marker Offset: ['21'] | Citation Marker: 1989 | Citation Offset: ['21'] | Citation Text: <S sid ="21" ssid = "21">Kupiec (1989) has experimented with the inclusion of networks to model mixed-order dependencies.</S> | Reference Offset: ['13'] | Reference Text: <S sid ="13" ssid = "13">In a first order model, Ci and Ci_l are random variables denoting the categories of the words at position i and (i - 1) in a text.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 6 | Reference Article: H89-2014.xml | Citing Article: H91-1046.xml | Citation Marker Offset: ['60'] | Citation Marker: Kupiec, 1989 | Citation Offset: ['60'] | Citation Text: <S sid ="60" ssid = "60">The vocabulary entry may be a word or an equivalence class based on categories (Kupiec, 1989).</S> | Reference Offset: ['29'] | Reference Text: <S sid ="29" ssid = "29">In this regard, word equivalence classes were used (Kupiec, 1989).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 7 | Reference Article: H89-2014.xml | Citing Article: C00-1081.xml | Citation Marker Offset: ['85'] | Citation Marker: Kupiec, 1989 | Citation Offset: ['85'] | Citation Text: <S sid ="85" ssid = "55">In a practical tagger (Kupiec, 1989), only the most frequent 100 words are lexicalized.</S> | Reference Offset: ['34'] | Reference Text: <S sid ="34" ssid = "34">In the 21 category model reported in Kupiec (1989) only 129 equivalence classes were required to cover a 30,000 word dictionary.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 8 | Reference Article: H89-2014.xml | Citing Article: H92-1022.xml | Citation Marker Offset: ['18'] | Citation Marker: 11 | Citation Offset: ['18'] | Citation Text: <S sid ="18" ssid = "18">The parameters of the model can be estimated from tagged (1, 3, 4, 6, 12] or untagged [2, 9, 11] text.</S> | Reference Offset: ['86'] | Reference Text: <S sid ="86" ssid = "86">Many of these neither contribute to the performance of the model, nor occur frequently enough to be estimated properly: e.g. P(Ci = determiner [ el1 -~ determiner, Ci2 = determiner).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 9 | Reference Article: H89-2014.xml | Citing Article: H92-1022.xml | Citation Marker Offset: ['9'] | Citation Marker: 11 | Citation Offset: ['9'] | Citation Text: <S sid ="9" ssid = "9">One area in which the statistical approach has done par­ ticularly well is automatic part of speech tagging, as­ signing each word in an input sentence its proper part of speech (1, 2, 3, 4, 6, 9, 11, 12].</S> | Reference Offset: ['7'] | Reference Text: <S sid ="7" ssid = "7">The determination of part-of-speech categories for words is an important problem in language modeling, because both the syntactic and semantic roles of words depend on their part-of-speech category (henceforth simply termed &quot;category&quot;).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 10 | Reference Article: H89-2014.xml | Citing Article: C92-1060.xml | Citation Marker Offset: ['124'] | Citation Marker: Kupiec, 1989 | Citation Offset: ['124'] | Citation Text: <S sid ="124" ssid = "19">Instead, only common words are represented individually; the rest of the words in the dictionary are partitioned into word equivalence classes (Kupiec, 1989)</S> | Reference Offset: ['34'] | Reference Text: <S sid ="34" ssid = "34">In the 21 category model reported in Kupiec (1989) only 129 equivalence classes were required to cover a 30,000 word dictionary.</S> | Discourse Facet: BLANK | Annotator: Predictions

