Citance Number: 1 | Reference Article: E03-1020.txt | Citing Article: W11-1104.txt | Citation Marker Offset: ['12'] | Citation Marker: Dorow and Widdows, 2003 | Citation Offset: ['12'] | Citation Text: <S sid ="12" ssid = "12">Current approaches have used clustering (Dorow and Widdows, 2003; Klapaftis and Manandhar, 2008) or statistical graph models (Klapaftis and Manandhar, 2010) to identify sense-specific subgraphs.</S> | Reference Offset: ['20'] | Reference Text: <S sid ="20" ssid = "3">Following the method in (Widdows and Dorow, 2002), we build a graph in which each node represents a noun and two nodes have an edge between them if they co-occur in lists more than a given number of times 1.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 2 | Reference Article: E03-1020.xml | Citing Article: S13-2038.xml | Citation Marker Offset: ['18'] | Citation Marker: 2003 | Citation Offset: ['18','19'] | Citation Text: <S sid ="18" ssid = "2">Dorow and Widdows (2003) use the BNC to build a cooccurrencegraph for nouns, based on a co-occurrence frequency threshold.</S><S sid ="19" ssid = "3">They perform Markov clustering on this graph.</S> | Reference Offset: ['20'] | Reference Text: <S sid ="20" ssid = "3">Following the method in (Widdows and Dorow, 2002), we build a graph in which each node represents a noun and two nodes have an edge between them if they co-occur in lists more than a given number of times 1.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 5 | Reference Article: E03-1020.xml | Citing Article: P04-1080.xml | Citation Marker Offset: ['199'] | Citation Marker: Dorow and Widdows, 2003 | Citation Offset: ['199','200','201'] | Citation Text: <S sid ="199" ssid = "9">The algorithm in (Dorow and Widdows, 2003) represented target noun word, its neighbors and their relationships using a graph in which each node denoted a noun and two nodes had an edge between them if they co-occurred with more than a given number of times.</S>	<S sid ="200" ssid = "10">Then senses of target word were iteratively learned by clustering the local graph of similar words around target word.</S><S sid ="201" ssid = "11">Their algorithm required a threshold as input, which controlled the number of senses.</S> | Reference Offset: ['20'] | Reference Text: <S sid ="20" ssid = "3">Following the method in (Widdows and Dorow, 2002), we build a graph in which each node represents a noun and two nodes have an edge between them if they co-occur in lists more than a given number of times 1.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 6 | Reference Article: E03-1020.xml | Citing Article: D10-1073.xml | Citation Marker Offset: ['35'] | Citation Marker: Dorow and Widdows, 2003 | Citation Offset: ['35','36','37'] | Citation Text: <S sid ="35" ssid = "16">Another graph-based method is presented in(Dorow and Widdows, 2003).</S><S sid ="36" ssid = "17">They extract onlynoun neighbours that appear in conjunctions or dis-junctions with the target word.</S><S sid ="37" ssid = "18">Additionally, theyextract second-order co-occurrences.</S> | Reference Offset: ['74'] | Reference Text: <S sid ="74" ssid = "30">In our simple model based on noun co-occurrences in lists, step 5 corresponds to rebuilding the graph under the restriction that the nodes in the new graph not co-occur (or at least not very often) with any of the cluster members already extracted.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 7 | Reference Article: E03-1020.xml | Citing Article: C04-1194.xml | Citation Marker Offset: ['21'] | Citation Marker: Dorow and Widdows, 2003 | Citation Offset: ['21'] | Citation Text: <S sid ="21" ssid = "21">The last trend, explored by (Véronis, 2003), (Dorow and Widdows, 2003) and (Rapp, 2003), starts from the cooccurrents of a word recorded from a corpus and builds its senses by gathering its cooccurrents according to their similarity or their dissimilarity.</S> | Reference Offset: ['40'] | Reference Text: <S sid ="40" ssid = "13">Let G, denote the local graph around the ambiguous word w. The adjacency matrix MG 4111) 11 41 4Wit ler,1110.1/.17, cgtoserek¦Ilt Figure 2: Local graph of the word wing of a graph G, is defined by setting (111G) pq equal to the weight of the edge between nodes v and v q . Normalizing the columns of A/G results in the Markov Matrix Taw whose entries (Thi,)pq can be interpreted as transition probability from v q to vv . It can easily be shown that the k-th power of TG lists the probabilities (TL )pq of a path of length k starting at node vq and ending at node V. The MCL-algorithm simulates flow in Gw by iteratively recomputing the set of transition probabilities via two steps, expansion and inflation.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 8 | Reference Article: E03-1020.xml | Citing Article: C04-1194.xml | Citation Marker Offset: ['27'] | Citation Marker: Dorow and Widdows, 2003 | Citation Offset: ['27'] | Citation Text: <S sid ="27" ssid = "5">This method, as the ones presented in (Véronis, 2003), (Dorow and Widdows, 2003) and (Rapp, 2003), relies on the following hypothesis: in the subgraph gathering the cooccurrents of a word, the number of relations between the cooccurrents defining a sense is higher than the number of relations that these cooccurrents have with those defining the other senses of the considered word.</S> | Reference Offset: ['20'] | Reference Text: <S sid ="20" ssid = "3">Following the method in (Widdows and Dorow, 2002), we build a graph in which each node represents a noun and two nodes have an edge between them if they co-occur in lists more than a given number of times 1.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 9 | Reference Article: E03-1020.xml | Citing Article: C04-1194.xml | Citation Marker Offset: ['157'] | Citation Marker: Dorow and Widdows, 2003 | Citation Offset: ['157'] | Citation Text: <S sid ="157" ssid = "1">As they rely on the detection of high-density areas in a network of cooccurrences, (Véronis, 2003) and (Dorow and Widdows, 2003) are the closest methods to ours.</S> | Reference Offset: ['20'] | Reference Text: <S sid ="20" ssid = "3">Following the method in (Widdows and Dorow, 2002), we build a graph in which each node represents a noun and two nodes have an edge between them if they co-occur in lists more than a given number of times 1.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 10 | Reference Article: E03-1020.xml | Citing Article: C04-1194.xml | Citation Marker Offset: ['160'] | Citation Marker: Dorow and Widdows, 2003 | Citation Offset: ['160'] | Citation Text: <S sid ="160" ssid = "4">In our case, we chose a more general approach by working at the level of a simi­larity graph: when the similarity of two words is given by their relation of cooccurrence, our situa­tion is comparable to the one of (Véronis, 2003) and (Dorow and Widdows, 2003)</S> | Reference Offset: ['40'] | Reference Text: <S sid ="40" ssid = "13">Let G, denote the local graph around the ambiguous word w. The adjacency matrix MG 4111) 11 41 4Wit ler,1110.1/.17, cgtoserek¦Ilt Figure 2: Local graph of the word wing of a graph G, is defined by setting (111G) pq equal to the weight of the edge between nodes v and v q . Normalizing the columns of A/G results in the Markov Matrix Taw whose entries (Thi,)pq can be interpreted as transition probability from v q to vv . It can easily be shown that the k-th power of TG lists the probabilities (TL )pq of a path of length k starting at node vq and ending at node V. The MCL-algorithm simulates flow in Gw by iteratively recomputing the set of transition probabilities via two steps, expansion and inflation.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 11 | Reference Article: E03-1020.xml | Citing Article: C04-1194.xml | Citation Marker Offset: ['165'] | Citation Marker: Dorow and Widdows, 2003 | Citation Offset: ['165'] | Citation Text: <S sid ="165" ssid = "9">From a global viewpoint, these two differences lead (Véronis, 2003) and (Dorow and Widdows, 2003) to build finer senses than ours.</S> | Reference Offset: ['20'] | Reference Text: <S sid ="20" ssid = "3">Following the method in (Widdows and Dorow, 2002), we build a graph in which each node represents a noun and two nodes have an edge between them if they co-occur in lists more than a given number of times 1.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 12 | Reference Article: E03-1020.xml | Citing Article: N07-3010.xml | Citation Marker Offset: ['73'] | Citation Marker: 2003 | Citation Offset: ['73'] | Citation Text: <S sid ="73" ssid = "32">The methodology of Dorow and Widdows (2003) was adopted: for the focus word, obtain its graph neighborhood (all vertices that are connected via edges to the focus word vertex and edges between these).</S> | Reference Offset: ['40'] | Reference Text: <S sid ="40" ssid = "13">Let G, denote the local graph around the ambiguous word w. The adjacency matrix MG 4111) 11 41 4Wit ler,1110.1/.17, cgtoserek¦Ilt Figure 2: Local graph of the word wing of a graph G, is defined by setting (111G) pq equal to the weight of the edge between nodes v and v q . Normalizing the columns of A/G results in the Markov Matrix Taw whose entries (Thi,)pq can be interpreted as transition probability from v q to vv . It can easily be shown that the k-th power of TG lists the probabilities (TL )pq of a path of length k starting at node vq and ending at node V. The MCL-algorithm simulates flow in Gw by iteratively recomputing the set of transition probabilities via two steps, expansion and inflation.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 13 | Reference Article: E03-1020.xml | Citing Article: W11-2214.xml | Citation Marker Offset: ['10'] | Citation Marker: Dorow and Widdows, 2003 | Citation Offset: ['10'] | Citation Text: <S sid ="10" ssid = "10">This unsupervised discovery process produces a sense inventory where the number of senses is corpus-driven and where senses may reflect additional usages not present in a predefined sense inventory, such as those for medicine or law (Dorow and Widdows, 2003).</S> | Reference Offset: ['20'] | Reference Text: <S sid ="20" ssid = "3">Following the method in (Widdows and Dorow, 2002), we build a graph in which each node represents a noun and two nodes have an edge between them if they co-occur in lists more than a given number of times 1.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 14 | Reference Article: E03-1020.xml | Citing Article: W11-2214.xml | Citation Marker Offset: ['80'] | Citation Marker: 2003 | Citation Offset: ['80'] | Citation Text: <S sid ="80" ssid = "10">We follow Pantel and Lin (2002) and Dorow and Widdows (2003) using the sentence as contexts and all words with a dependency path of length 3 or less, with the last word and its relation as a feature.</S> | Reference Offset: ['40'] | Reference Text: <S sid ="40" ssid = "13">Let G, denote the local graph around the ambiguous word w. The adjacency matrix MG 4111) 11 41 4Wit ler,1110.1/.17, cgtoserek¦Ilt Figure 2: Local graph of the word wing of a graph G, is defined by setting (111G) pq equal to the weight of the edge between nodes v and v q . Normalizing the columns of A/G results in the Markov Matrix Taw whose entries (Thi,)pq can be interpreted as transition probability from v q to vv . It can easily be shown that the k-th power of TG lists the probabilities (TL )pq of a path of length k starting at node vq and ending at node V. The MCL-algorithm simulates flow in Gw by iteratively recomputing the set of transition probabilities via two steps, expansion and inflation.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 15 | Reference Article: E03-1020.xml | Citing Article: W06-3812.xml | Citation Marker Offset: ['176'] | Citation Marker: Dorow and Widdows, 2003 | Citation Offset: ['176','178'] | Citation Text: <S sid ="176" ssid = "50">Similar to the approach as presented in (Dorow and Widdows, 2003) we construct a word graph.</S><S sid ="178" ssid = "52">Dorow and Widdows construct a graph for a target word w by taking the sub-graph induced by the neighborhood of w (without w) and clustering it with MCL.</S> | Reference Offset: ['40'] | Reference Text: <S sid ="40" ssid = "13">Let G, denote the local graph around the ambiguous word w. The adjacency matrix MG 4111) 11 41 4Wit ler,1110.1/.17, cgtoserek¦Ilt Figure 2: Local graph of the word wing of a graph G, is defined by setting (111G) pq equal to the weight of the edge between nodes v and v q . Normalizing the columns of A/G results in the Markov Matrix Taw whose entries (Thi,)pq can be interpreted as transition probability from v q to vv . It can easily be shown that the k-th power of TG lists the probabilities (TL )pq of a path of length k starting at node vq and ending at node V. The MCL-algorithm simulates flow in Gw by iteratively recomputing the set of transition probabilities via two steps, expansion and inflation.</S> | Discourse Facet: BLANK | Annotator: Predictions

