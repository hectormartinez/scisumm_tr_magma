Citance Number: 1 | Reference Article: C08-1098.txt | Citing Article: C10-2023.txt | Citation Marker Offset: ['122'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['122'] | Citation Text: <S sid ="122" ssid = "9">Additional German tags are obtained using the RFTagger 2 toolkit, which annotates text with fine-grained part-of-speech tags (Schmid and Laws, 2008) with a vocabulary of more than 700 tags containing rich morpho-syntactic information (gender, number, case, tense, etc.).</S> | Reference Offset: ['4'] | Reference Text: <S sid ="4" ssid = "4">A Hidden-Markov-Model part-of-speech tagger (Brants, 2000, e.g.) computes the most probable POS tag sequence tˆN = tˆ1, ..., tˆN for a given word sequence wN . POS taggers are usually trained on corpora with between 50 and 150 different POS tags.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 2 | Reference Article: C08-1098.txt | Citing Article: D12-1133.txt | Citation Marker Offset: ['208'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['208'] | Citation Text: <S sid ="208" ssid = "99">For German, we obtain a tagging accuracy of 97.24, which is close to the 97.39 achieved by the RFTagger (Schmid and Laws, 2008), which to our knowledge is the best tagger for German</S> | Reference Offset: ['122'] | Reference Text: <S sid ="122" ssid = "2">The results were compared to those obtained with the TnT tagger (Brants, 2000) and the SVMTool (Gime´nez and Ma`rquez, 2004), which is based on support vector machines.7 The training of the SVMTool took more than a day.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 3 | Reference Article: C08-1098.txt | Citing Article: D12-1133.txt | Citation Marker Offset: ['228'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['228'] | Citation Text: <S sid ="228" ssid = "119">For German, finally, we see the greatest improvement with k = 3 tional words that are not found in the training corpus and additional tags for words that do occur in the training data (Schmid and Laws, 2008).</S> | Reference Offset: ['100'] | Reference Text: <S sid ="100" ssid = "6">The tagger may use an external lexicon which supplies entries for additional words which are not found in the training corpus, and additional tags for words which did occur in the training data.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 4 | Reference Article: C08-1098.txt | Citing Article: D13-1032.txt | Citation Marker Offset: ['212'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['212'] | Citation Text: <S sid ="212" ssid = "20">We use the following baselines: SVMTool (GimeÂ´nez and Ma`rquez, 2004), an SVM-based dis- criminative tagger; RFTagger (Schmid and Laws, 2008), an n-gram Hidden Markov Model (HMM) tagger developed for POS+MORPH tagging;</S> | Reference Offset: ['122'] | Reference Text: <S sid ="122" ssid = "2">The results were compared to those obtained with the TnT tagger (Brants, 2000) and the SVMTool (Gime´nez and Ma`rquez, 2004), which is based on support vector machines.7 The training of the SVMTool took more than a day.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 5 | Reference Article: C08-1098.txt | Citing Article: D13-1033.txt | Citation Marker Offset: ['176'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['176'] | Citation Text: <S sid ="176" ssid = "139">For German, we show results for RFTagger (Schmid and Laws, 2008).</S> | Reference Offset: ['60'] | Reference Text: <S sid ="60" ssid = "21">The motivation was that a tree which predicts a single value (say verb) does not fragment the data with tests which are only relevant for the distinction of two other values (e.g. article and possessive pronoun).2 Furthermore, we observed that such two-class decision trees require no optimization of the pruning threshold (see also section 2.2.) The tree induction algorithm only considers binary tests, which check whether some particular attribute is present or not.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 6 | Reference Article: C08-1098.txt | Citing Article: E09-1079.txt | Citation Marker Offset: ['121'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['121'] | Citation Text: <S sid ="121" ssid = "7">The decisiontree uses different context features for the predic tion of different attributes (Schmid and Laws, 2008).</S> | Reference Offset: ['33'] | Reference Text: <S sid ="33" ssid = "33">By (1) decomposing the context probability of ADJA.Pos.Nom.Sg.Neut into a product of attribute probabilities p(ADJA | 2:ART, 2:ART.Def, 2:ART.Nom, 2:ART.Sg, 2:ART.Neut, 1:PART, 1:PART.Zu) ∗ p(Pos| 2:ART, 2:ART.Def, 2:ART.Nom, 2:ART.Sg, 2:ART.Neut, 1:PART, 1:PART.Zu, 0:ADJA) ∗ p(Nom | 2:ART, 2:ART.Def, 2:ART.Nom, 2:ART.Sg, 2:ART.Neut, 1:PART, 1:PART.Zu, 0:ADJA, 0:ADJA.Pos) ∗ p(Sg | 2:ART, 2:ART.Def, 2:ART.Nom, 2:ART.Sg, 2:ART.Neut, 1:PART, 1:PART.Zu, 0:ADJA, 0:ADJA.Pos, 0:ADJA.Nom) ∗ p(Neut | 2:ART, 2:ART.Def, 2:ART.Nom, 2:ART.Sg, 2:ART.Neut, 1:PART, 1:PART.Zu, 0:ADJA, 0:ADJA.Pos, 0:ADJA.Nom, 0:ADJA.Sg) and (2) selecting the relevant context attributes for the prediction of each attribute, we obtain the ∗ p(Sg | 2:ART.Sg, 1:PART.Zu, 0:ADJA) ∗ p(Neut | 2:ART.Neut, 1:PART.Zu, 0:ADJA) The conditional probability of each attribute is 1.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 7 | Reference Article: C08-1098.txt | Citing Article: P10-1020.txt | Citation Marker Offset: ['159'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['159'] | Citation Text: <S sid ="159" ssid = "71">However, we found that we achieved better accuracy by using RFTagger (Schmid and Laws, 2008), which tags nouns with their morphological case.</S> | Reference Offset: ['60'] | Reference Text: <S sid ="60" ssid = "21">The motivation was that a tree which predicts a single value (say verb) does not fragment the data with tests which are only relevant for the distinction of two other values (e.g. article and possessive pronoun).2 Furthermore, we observed that such two-class decision trees require no optimization of the pruning threshold (see also section 2.2.) The tree induction algorithm only considers binary tests, which check whether some particular attribute is present or not.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 8 | Reference Article: C08-1098.txt | Citing Article: P10-1068.txt | Citation Marker Offset: ['42'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['42'] | Citation Text: <S sid ="42" ssid = "31">With respect to morphosyntactic annotations (parts of speech, pos) and morphological annotations (morph), five Annotation Models for German are currently available: STTS (Schiller et al., 1999, pos), TIGER (Brants and Hansen, 2002, morph), Morphisto (Zielinski and Simon, 2008, pos, morph), RFTagger (Schmid and Laws, 2008, pos, morph)</S> | Reference Offset: ['12'] | Reference Text: <S sid ="12" ssid = "12">The German Tiger treebank (Brants et al., 2002) is an example of a corpus with a more fine-grained tagset (over 700 tags overall).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 9 | Reference Article: C08-1098.txt | Citing Article: P10-1068.txt | Citation Marker Offset: ['74'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['74'] | Citation Text: <S sid ="74" ssid = "63">Analogously, the corresponding RFTagger analysis (Schmid and Laws, 2008) given in (5) can be transformed into a description in terms of the OLiA Reference Model such as in (6).</S> | Reference Offset: ['109'] | Reference Text: <S sid ="109" ssid = "15">The main differences of our tag- ger to a standard trigram tagger are that the order of the Markov model (the k in equation 1) is not fixed 4 This is the reason why the attribute tests in figure 1 used complex attributes such as ART.Nom rather than Nom.The smoothed estimates of p(tag|word) are di vided by the prior probability p(tag) of the tag and used instead of p(word|tag).5 4.2 Unknown Words.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 10 | Reference Article: C08-1098.txt | Citing Article: P10-1068.txt | Citation Marker Offset: ['81'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['81'] | Citation Text: <S sid ="81" ssid = "6">(iii) the RFTagger that performs part of speech and morphological analysis (Schmid and Laws, 2008)</S> | Reference Offset: ['4'] | Reference Text: <S sid ="4" ssid = "4">A Hidden-Markov-Model part-of-speech tagger (Brants, 2000, e.g.) computes the most probable POS tag sequence tˆN = tˆ1, ..., tˆN for a given word sequence wN . POS taggers are usually trained on corpora with between 50 and 150 different POS tags.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 11 | Reference Article: C08-1098.txt | Citing Article: W10-1704.txt | Citation Marker Offset: ['32'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['32'] | Citation Text: <S sid ="32" ssid = "18">These normalization patterns use the lemma information computed by the TreeTagger and the fine-grained POS information computed by the RFTagger (Schmid and Laws, 2008), which uses a tagset containing approximately 800 tags.</S> | Reference Offset: ['162'] | Reference Text: <S sid ="162" ssid = "42">With a context of two preceding POS tags (similar to the trigram tagger TnT), our tagger outperforms TnT by 0.7% on the default tagset, by 1% on the refined tagset, and by 1.1% on the refined tagset plus the additional lexicon.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 12 | Reference Article: C08-1098.txt | Citing Article: W10-1727.txt | Citation Marker Offset: ['41'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['41'] | Citation Text: <S sid ="41" ssid = "4">For German we used morphologically rich tags from RFTagger (Schmid and Laws, 2008), that contains morphological information such as case, number, and gender for nouns and tense for verbs.</S> | Reference Offset: ['127'] | Reference Text: <S sid ="127" ssid = "7">It is annotated with POS tags from the coarse-grained STTS tagset and with additional features encoding information about number, gender, case, person, degree, tense, and mood.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 13 | Reference Article: C08-1098.txt | Citing Article: W11-2135.txt | Citation Marker Offset: ['49'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['49'] | Citation Text: <S sid ="49" ssid = "4">For German, the fine-grained POS information used for pre-processing was computed by the RFTagger (Schmid and Laws, 2008).</S> | Reference Offset: ['60'] | Reference Text: <S sid ="60" ssid = "21">The motivation was that a tree which predicts a single value (say verb) does not fragment the data with tests which are only relevant for the distinction of two other values (e.g. article and possessive pronoun).2 Furthermore, we observed that such two-class decision trees require no optimization of the pruning threshold (see also section 2.2.) The tree induction algorithm only considers binary tests, which check whether some particular attribute is present or not.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 14 | Reference Article: C08-1098.txt | Citing Article: W11-2145.txt | Citation Marker Offset: ['101'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['101','102'] | Citation Text: <S sid ="101" ssid = "92">The part-of-speeches were generated using the TreeTagger and the RFTagger (Schmid and Laws, 2008), which produces more fine-grained tags that include also person, gender and case information.</S><S sid ="102" ssid = "93">While the TreeTagger assigns 54 different POS tags to the 357K German words in the corpus, the RFTagger produces 756 different fine-grained tags on the same corpus.</S> | Reference Offset: ['139'] | Reference Text: <S sid ="139" ssid = "19">In order to provide the tagger with some information about the case of prepositions, a second training corpus was created in which prepositions which always select the same case, such as durch (through), were annotated with this case (APPR.Acc).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 15 | Reference Article: C08-1098.txt | Citing Article: W11-2147.txt | Citation Marker Offset: ['26'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['26'] | Citation Text: <S sid ="26" ssid = "15">For German, the POS and morphological tags were obtained from RFTagger (Schmid and Laws, 2008) which provides morphological information such as case, number and gender for nouns and tense for verbs.</S> | Reference Offset: ['127'] | Reference Text: <S sid ="127" ssid = "7">It is annotated with POS tags from the coarse-grained STTS tagset and with additional features encoding information about number, gender, case, person, degree, tense, and mood.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 16 | Reference Article: C08-1098.txt | Citing Article: W12-3141.txt | Citation Marker Offset: ['89'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['89'] | Citation Text: <S sid ="89" ssid = "8">All parallel corpora were POS-tagged with the TreeTagger (Schmid, 1994); in addition, for German, fine-grained POS labels were also needed for pre-processing and were obtained using the RFTagger (Schmid and Laws, 2008).</S> | Reference Offset: ['225'] | Reference Text: <S sid ="225" ssid = "2">In experiments with German and Czech corpora, this method achieved a higher tagging accuracy than two state-of-the-art general-purpose POS taggers (TnT and SVMTool).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 17 | Reference Article: C08-1098.txt | Citing Article: W12-3144.txt | Citation Marker Offset: ['127'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['127'] | Citation Text: <S sid ="127" ssid = "113">The POS tags are generated with the RFTagger (Schmid and Laws, 2008) for German, which produces fine-grained tags that include person, gender and case information.</S> | Reference Offset: ['60'] | Reference Text: <S sid ="60" ssid = "21">The motivation was that a tree which predicts a single value (say verb) does not fragment the data with tests which are only relevant for the distinction of two other values (e.g. article and possessive pronoun).2 Furthermore, we observed that such two-class decision trees require no optimization of the pruning threshold (see also section 2.2.) The tree induction algorithm only considers binary tests, which check whether some particular attribute is present or not.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 18 | Reference Article: C08-1098.txt | Citing Article: W12-3402.txt | Citation Marker Offset: ['78'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['78'] | Citation Text: <S sid ="78" ssid = "16">Morphological information is annotated using RFTagger (Schmid and Laws, 2008), a state-of-the-art morphological tagger based on decision trees and a large context window (which allows it to model morphological agreement more accurately than a normal trigram-based sequence tagger).</S> | Reference Offset: ['122'] | Reference Text: <S sid ="122" ssid = "2">The results were compared to those obtained with the TnT tagger (Brants, 2000) and the SVMTool (Gime´nez and Ma`rquez, 2004), which is based on support vector machines.7 The training of the SVMTool took more than a day.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 19 | Reference Article: C08-1098.txt | Citing Article: W13-2204.txt | Citation Marker Offset: ['35'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['35'] | Citation Text: <S sid ="35" ssid = "6">All parallel corpora were POS-tagged with the TreeTagger (Schmid, 1994); in addition, for German, fine-grained POS labels were also needed for pre-processing and were obtained using the RFTagger (Schmid and Laws, 2008).</S> | Reference Offset: ['225'] | Reference Text: <S sid ="225" ssid = "2">In experiments with German and Czech corpora, this method achieved a higher tagging accuracy than two state-of-the-art general-purpose POS taggers (TnT and SVMTool).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 20 | Reference Article: C08-1098.txt | Citing Article: W13-2210.txt | Citation Marker Offset: ['37'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['37'] | Citation Text: <S sid ="37" ssid = "4">In order to train the POS-based reordering model, probabilistic rules were learned based on the POS tags from the TreeTagger (Schmid and Laws, 2008) of the training corpus and the alignment.</S> | Reference Offset: ['124'] | Reference Text: <S sid ="124" ssid = "4">We took standard features from a 5 word window and M4LRL training without optimization of the regular- ization parameter C. In a second experiment, our tagger was also evaluated on the Czech Academic corpus 1.0 (Hladka´ et al., 2007) and compared to the TnT tag- ger.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 21 | Reference Article: C08-1098.txt | Citing Article: W13-2210.txt | Citation Marker Offset: ['85'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['85'] | Citation Text: <S sid ="85" ssid = "8">The POS tags are generated using the RFTagger (Schmid and Laws, 2008) for German.</S> | Reference Offset: ['4'] | Reference Text: <S sid ="4" ssid = "4">A Hidden-Markov-Model part-of-speech tagger (Brants, 2000, e.g.) computes the most probable POS tag sequence tˆN = tˆ1, ..., tˆN for a given word sequence wN . POS taggers are usually trained on corpora with between 50 and 150 different POS tags.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 22 | Reference Article: C08-1098.txt | Citing Article: W13-2211.txt | Citation Marker Offset: ['84'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['84'] | Citation Text: <S sid ="84" ssid = "73">We lemmatized German articles, adjectives (only positive form), for some pronouns and for nouns in order to remove the lexical redundancy (e.g., Bildes as Bild) by using the fine- grained part-of-speech tags generated by RFTagger (Schmid and Laws, 2008).</S> | Reference Offset: ['60'] | Reference Text: <S sid ="60" ssid = "21">The motivation was that a tree which predicts a single value (say verb) does not fragment the data with tests which are only relevant for the distinction of two other values (e.g. article and possessive pronoun).2 Furthermore, we observed that such two-class decision trees require no optimization of the pruning threshold (see also section 2.2.) The tree induction algorithm only considers binary tests, which check whether some particular attribute is present or not.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 23 | Reference Article: C08-1098.txt | Citing Article: W13-2228.txt | Citation Marker Offset: ['134'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['134'] | Citation Text: <S sid ="134" ssid = "14">6.1.1 POS Tagging We use RFTagger (Schmid and Laws, 2008) for POS tagging.</S> | Reference Offset: ['2'] | Reference Text: <S sid ="2" ssid = "2">It is based on three ideas: (1) splitting of the POS tags into attribute vectors and decomposition of the contextual POS probabilities of the HMM into a product of attribute probabilities, (2) estimation of the contextual probabilities with decision trees, and (3) use of high-order HMMs.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 24 | Reference Article: C08-1098.txt | Citing Article: W13-2230.txt | Citation Marker Offset: ['35'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['35'] | Citation Text: <S sid ="35" ssid = "6">In the second step, the normalized training data is annotated with Part-of-Speech tags (PoS-tags) and word lemmas using RFTagger (Schmid and Laws, 2008) which was trained on the French tree- bank (AbeilleÂ´ et al., 2003).</S> | Reference Offset: ['124'] | Reference Text: <S sid ="124" ssid = "4">We took standard features from a 5 word window and M4LRL training without optimization of the regular- ization parameter C. In a second experiment, our tagger was also evaluated on the Czech Academic corpus 1.0 (Hladka´ et al., 2007) and compared to the TnT tag- ger.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 25 | Reference Article: C08-1098.txt | Citing Article: W13-2230.txt | Citation Marker Offset: ['58'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['58'] | Citation Text: <S sid ="58" ssid = "11">Morphological analysis and resources The morphological analysis of the French training data is obtained using RFTagger, which is designed for annotating fine-grained morphological tags (Schmid and Laws, 2008).</S> | Reference Offset: ['60'] | Reference Text: <S sid ="60" ssid = "21">The motivation was that a tree which predicts a single value (say verb) does not fragment the data with tests which are only relevant for the distinction of two other values (e.g. article and possessive pronoun).2 Furthermore, we observed that such two-class decision trees require no optimization of the pruning threshold (see also section 2.2.) The tree induction algorithm only considers binary tests, which check whether some particular attribute is present or not.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 26 | Reference Article: C08-1098.txt | Citing Article: W13-2230.txt | Citation Marker Offset: ['83'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['83'] | Citation Text: <S sid ="83" ssid = "2">Tagging and tagging errors For tagging, we use a version of RFTagger (Schmid and Laws, 2008)</S> | Reference Offset: ['2'] | Reference Text: <S sid ="2" ssid = "2">It is based on three ideas: (1) splitting of the POS tags into attribute vectors and decomposition of the contextual POS probabilities of the HMM into a product of attribute probabilities, (2) estimation of the contextual probabilities with decision trees, and (3) use of high-order HMMs.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 28 | Reference Article: C08-1098.txt | Citing Article: W13-2302.txt | Citation Marker Offset: ['87'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['87'] | Citation Text: <S sid ="87" ssid = "65">The results presented here were achieved using the RFTagger (Schmid and Laws, 2008)</S> | Reference Offset: ['122'] | Reference Text: <S sid ="122" ssid = "2">The results were compared to those obtained with the TnT tagger (Brants, 2000) and the SVMTool (Gime´nez and Ma`rquez, 2004), which is based on support vector machines.7 The training of the SVMTool took more than a day.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 29 | Reference Article: C08-1098.txt | Citing Article: W13-2708.txt | Citation Marker Offset: ['111'] | Citation Marker: Schmid and Laws, 2008 | Citation Offset: ['111'] | Citation Text: <S sid ="111" ssid = "54">So far, the Complex Concept Builder implements tokenization (Schmid, 2009), lemmatisation (Schmid, 1995), part-of-speech tagging (Schmid and Laws, 2008)</S> | Reference Offset: ['4'] | Reference Text: <S sid ="4" ssid = "4">A Hidden-Markov-Model part-of-speech tagger (Brants, 2000, e.g.) computes the most probable POS tag sequence tˆN = tˆ1, ..., tˆN for a given word sequence wN . POS taggers are usually trained on corpora with between 50 and 150 different POS tags.</S> | Discourse Facet: BLANK | Annotator: Predictions

