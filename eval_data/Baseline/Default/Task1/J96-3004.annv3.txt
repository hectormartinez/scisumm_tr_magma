Citance Number: 1 | Reference Article: J96-3004.xml | Citing Article: A00-2032.xml | Citation Marker Offset: ['142'] | Citation Marker: 1996 | Citation Offset: ['141','142'] | Citation Text: <S sid ="141" ssid = "10">Chinese According to Sproat et al.</S><S sid ="142" ssid = "11">(1996), most prior work in Chinese segmentation has exploited lexical knowledge bases; indeed, the authors assert that they were aware of only one previously pubÂ­ lished instance (the mutual-information method of Sproat and Shih (1990)) of a purely statistical apÂ­ proach.</S> | Reference Offset: ['21'] | Reference Text: <S sid ="21" ssid = "21">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion &quot;word&quot; has never played a role in Chinese philological tradition, and the idea that Chinese lacks any­ thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 3 | Reference Article: J96-3004.xml | Citing Article: C00-2095.xml | Citation Marker Offset: ['80'] | Citation Marker: Sproat ct a.l., 1996 | Citation Offset: ['80'] | Citation Text: <S sid ="80" ssid = "25">As (Sproat ct a.l., 1996) testify, several native Chinese speakers do not always agree on one unique tokeniza.tion for a. given sentence.</S> | Reference Offset: ['16'] | Reference Text: <S sid ="16" ssid = "16">com §Cambridge, UK Email: nc201@eng.cam.ac.uk © 1996 Association for Computational Linguistics (a) B ) ( , : &amp; ; ? &apos; H o w d o y o u s a y o c t o p u s i n J a p a n e s e ? &apos; (b) P l a u s i b l e S e g m e n t a t i o n I B X I I 1 : &amp; I 0 0 r i 4 w e n 2 z h a n g l y u 2 z e n 3 m e 0 s h u o l &apos; J a p a n e s e &apos; &apos; o c t o p u s &apos; &apos; h o w &apos; &apos; s a y &apos; (c) Figure 1 I m p l a u s i b l e S e g m e n t a t i o n [§] lxI 1:&amp;I ri4 wen2 zhangl yu2zen3 me0 shuol &apos;Japan&apos; &apos;essay&apos; &apos;fish&apos; &apos;how&apos; &apos;say&apos; A Chinese sentence in (a) illustrating the lack of word boundaries.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 4 | Reference Article: J96-3004.xml | Citing Article: C02-1049.xml | Citation Marker Offset: ['58'] | Citation Marker: Sproat et al, 1996 | Citation Offset: ['58'] | Citation Text: <S sid ="58" ssid = "39">Conventionally a word segmentation process identifies the words in input text by matching lexical entries and resolving the ambiguous matching (Chen &amp; Liu, 1992, Sproat et al, 1996).</S> | Reference Offset: ['115'] | Reference Text: <S sid ="115" ssid = "53">Others depend upon various lexical heuris­ tics: for example Chen and Liu (1992) attempt to balance the length of words in a three-word window, favoring segmentations that give approximately equal length for each word.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 5 | Reference Article: J96-3004.xml | Citing Article: C02-1049.xml | Citation Marker Offset: ['127'] | Citation Marker: Sproat et al, 1996 | Citation Offset: ['124','127'] | Citation Text: <S sid ="124" ssid = "105">Mutu al infor matio n-like statist ics are very often adopt ed in meas uring assoc iation stren gth msi (?)</S><S sid ="127" ssid = "108">dsi +1 () combine (i, i + 1) 1993, Sproat et al, 1996)</S> | Reference Offset: ['242'] | Reference Text: <S sid ="242" ssid = "106">The first probability is estimated from a name count in a text database, and the rest of the probabilities are estimated from a large list of personal names.n Note that in Chang et al.&apos;s model the p(rule 9) is estimated as the product of the probability of finding G 1 in the first position of a two-hanzi given name and the probability of finding G2 in the second position of a two-hanzi given name, and we use essentially the same estimate here, with some modifications as described later on.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 6 | Reference Article: J96-3004.xml | Citing Article: C02-1080.xml | Citation Marker Offset: ['20'] | Citation Marker: Sproat et al. 96 | Citation Offset: ['20','21'] | Citation Text: <S sid ="20" ssid = "20">Chinese NE recognition is much more difficult than that in English due to two major problems.</S><S sid ="21" ssid = "21">The first is the word segmentation problem (Sproat et al. 96, Palmer 97).</S> | Reference Offset: ['242'] | Reference Text: <S sid ="242" ssid = "106">The first probability is estimated from a name count in a text database, and the rest of the probabilities are estimated from a large list of personal names.n Note that in Chang et al.&apos;s model the p(rule 9) is estimated as the product of the probability of finding G 1 in the first position of a two-hanzi given name and the probability of finding G2 in the second position of a two-hanzi given name, and we use essentially the same estimate here, with some modifications as described later on.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 7 | Reference Article: J96-3004.xml | Citing Article: C02-1143.xml | Citation Marker Offset: ['107'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['107'] | Citation Text: <S sid ="107" ssid = "48">We used a maximum- matching algorithm and a dictionary compiled from the CTB (Sproat et al., 1996; Xue, 2001) to do segmentation</S> | Reference Offset: ['140'] | Reference Text: <S sid ="140" ssid = "4">Then each arc of D maps either from an element of H to an element of p, or from E-i.e., the empty string-to an element of P. More specifically, each word is represented in the dictionary as a sequence of arcs, starting from the initial state of D and labeled with an element 5 of Hxp, which is terminated with a weighted arc labeled with an element of Ex P. The weight represents the estimated cost (negative log probability) of the word.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 8 | Reference Article: J96-3004.xml | Citing Article: E09-1063.xml | Citation Marker Offset: ['107'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['107'] | Citation Text: <S sid ="107" ssid = "4">First of all, it is really difficult to build a reliable and objective gold-standard given the fact that there is only 70% agreement between native speakers on this task (Sproat et al., 1996).</S> | Reference Offset: ['172'] | Reference Text: <S sid ="172" ssid = "36">Clearly this is not the only way to estimate word-frequencies, however, and one could consider applying other methods: in partic­ ular since the problem is similar to the problem of assigning part-of-speech tags to an untagged corpus given a lexicon and some initial estimate of the a priori probabilities for the tags, one might consider a more sophisticated approach such as that described in Kupiec (1992); one could also use methods that depend on a small hand-tagged seed corpus, as suggested by one reviewer.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 9 | Reference Article: J96-3004.xml | Citing Article: I05-3031.xml | Citation Marker Offset: ['7'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['6','7'] | Citation Text: <S sid ="6" ssid = "6">The Chinese word segmentation is a nontrivial task because no explicit delimiters (like spaces in English) are used for word separation.</S><S sid ="7" ssid = "7">As the task is an important precursor to many natural language processing systems, it receives a lot of attentions in the literature for the past decade (Wu and Tseng, 1993; Sproat et al., 1996).</S> | Reference Offset: ['21'] | Reference Text: <S sid ="21" ssid = "21">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion &quot;word&quot; has never played a role in Chinese philological tradition, and the idea that Chinese lacks any­ thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 10 | Reference Article: J96-3004.xml | Citing Article: J00-3004.xml | Citation Marker Offset: ['42'] | Citation Marker: 1996 | Citation Offset: ['42'] | Citation Text: <S sid ="42" ssid = "42">According to Sproat et al. {1996) and Wu and Fung {1994), experiments show that only about 75% agreement between native speakers is to be expected on the &quot;correct&quot; segmentation, and the figure reduces as more people become involved.</S> | Reference Offset: ['408'] | Reference Text: <S sid ="408" ssid = "11">This is not to say that a set of standards by which a particular segmentation would count as correct and another incorrect could not be devised; indeed, such standards have been proposed and include the published PRCNSC (1994) and ROCLING (1993), as well as the unpublished Linguistic Data Consortium standards (ca.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 11 | Reference Article: J96-3004.xml | Citing Article: J00-3004.xml | Citation Marker Offset: ['96'] | Citation Marker: 1996 | Citation Offset: ['96','97'] | Citation Text: <S sid ="96" ssid = "41">Sproat et al.</S><S sid ="97" ssid = "42">(1996) implement special recognizers not only for Chinese names and transliterated foreign names, but for components of morphologically obtained words as well.</S> | Reference Offset: ['91'] | Reference Text: <S sid ="91" ssid = "29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 12 | Reference Article: J96-3004.xml | Citing Article: J04-1004.xml | Citation Marker Offset: ['53'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['53'] | Citation Text: <S sid ="53" ssid = "53">In Chinese text segmentation there are three basic approaches (Sproat et al. 1996): pure heuristic, pure statistical, and a hybrid of the two.</S> | Reference Offset: ['242'] | Reference Text: <S sid ="242" ssid = "106">The first probability is estimated from a name count in a text database, and the rest of the probabilities are estimated from a large list of personal names.n Note that in Chang et al.&apos;s model the p(rule 9) is estimated as the product of the probability of finding G 1 in the first position of a two-hanzi given name and the probability of finding G2 in the second position of a two-hanzi given name, and we use essentially the same estimate here, with some modifications as described later on.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 13 | Reference Article: J96-3004.xml | Citing Article: J04-1004.xml | Citation Marker Offset: ['113'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['113'] | Citation Text: <S sid ="113" ssid = "9">There are several commonly used segmentation methods such as forward maximum matching and backward maximum matching(Teahan et al. 2000; Dai, Loh, and Khoo 1999; Sproat et al. 1996).</S> | Reference Offset: ['124'] | Reference Text: <S sid ="124" ssid = "62">Several systems propose statistical methods for handling unknown words (Chang et al. 1992; Lin, Chiang, and Su 1993; Peng and Chang 1993).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 14 | Reference Article: J96-3004.xml | Citing Article: J04-1004.xml | Citation Marker Offset: ['211'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['211'] | Citation Text: <S sid ="211" ssid = "32">In addition, there is no commonly accepted standard for evaluating the performance of word extraction methods, and it is very hard to decide whether a word is meaningful or not (Sproat et al. 1996).</S> | Reference Offset: ['433'] | Reference Text: <S sid ="433" ssid = "36">While Gan&apos;s system incorporates fairly sophisticated models of various linguistic information, it has the drawback that it has only been tested with a very small lexicon (a few hundred words) and on a very small test set (thirty sentences); there is therefore serious concern as to whether the methods that he discusses are scalable.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 15 | Reference Article: J96-3004.xml | Citing Article: J04-1004.xml | Citation Marker Offset: ['321'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['321'] | Citation Text: <S sid ="321" ssid = "7">As even human judges differ when facing the task of segmenting a text into words and test corpora differ from system to system (Sproat et al. 1996), it is very difficult to compare two methods.</S> | Reference Offset: ['130'] | Reference Text: <S sid ="130" ssid = "68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 16 | Reference Article: J96-3004.xml | Citing Article: J05-4005.xml | Citation Marker Offset: ['88'] | Citation Marker: 1996 | Citation Offset: ['88','89'] | Citation Text: <S sid ="88" ssid = "24">A previous work along this line is Sproat et al.</S><S sid ="89" ssid = "25">(1996), which is based on weighted finite-state transducers (FSTs).</S> | Reference Offset: ['141'] | Reference Text: <S sid ="141" ssid = "5">Next, we represent the input sentence as an unweighted finite-state acceptor (FSA) I over H. Let us assume the existence of a function Id, which takes as input an FSA A, and produces as output a transducer that maps all and only the strings of symbols accepted by A to themselves (Kaplan and Kay 1994).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 17 | Reference Article: J96-3004.xml | Citing Article: J05-4005.xml | Citation Marker Offset: ['126'] | Citation Marker: 1996 | Citation Offset: ['125','126'] | Citation Text: <S sid ="125" ssid = "61">As shown in Sproat et al.</S><S sid ="126" ssid = "62">(1996), the rate of agreement between two human judges is less than 80%.</S> | Reference Offset: ['325'] | Reference Text: <S sid ="325" ssid = "34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement.15 One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix, computing a classical metric multidimensional scaling (Torgerson 1958; Becker, Chambers, Wilks 1988) on that dis­ tance matrix, and plotting the first two most significant dimensions.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 18 | Reference Article: J96-3004.xml | Citing Article: J05-4005.xml | Citation Marker Offset: ['132'] | Citation Marker: 1996 | Citation Offset: ['131','132'] | Citation Text: <S sid ="131" ssid = "67">Similarly, Sproat et al.</S><S sid ="132" ssid = "68">(1996) also uses multiple human judges.</S> | Reference Offset: ['244'] | Reference Text: <S sid ="244" ssid = "108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.&apos;s Model.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 19 | Reference Article: J96-3004.xml | Citing Article: J05-4005.xml | Citation Marker Offset: ['490'] | Citation Marker: 1996 | Citation Offset: ['489','490'] | Citation Text: <S sid ="489" ssid = "153">The Chinese person-name model is a modified version of that described in Sproat et al.</S><S sid ="490" ssid = "154">(1996).</S> | Reference Offset: ['242'] | Reference Text: <S sid ="242" ssid = "106">The first probability is estimated from a name count in a text database, and the rest of the probabilities are estimated from a large list of personal names.n Note that in Chang et al.&apos;s model the p(rule 9) is estimated as the product of the probability of finding G 1 in the first position of a two-hanzi given name and the probability of finding G2 in the second position of a two-hanzi given name, and we use essentially the same estimate here, with some modifications as described later on.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 20 | Reference Article: J96-3004.xml | Citing Article: J11-1005.xml | Citation Marker Offset: ['123'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['123'] | Citation Text: <S sid ="123" ssid = "14">Experiments have shown that there is only about 75% agreement among native speakers regarding the correct word segmentation (Sproat et al. 1996).</S> | Reference Offset: ['325'] | Reference Text: <S sid ="325" ssid = "34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement.15 One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix, computing a classical metric multidimensional scaling (Torgerson 1958; Becker, Chambers, Wilks 1988) on that dis­ tance matrix, and plotting the first two most significant dimensions.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 21 | Reference Article: J96-3004.xml | Citing Article: J11-3001.xml | Citation Marker Offset: ['326'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['326'] | Citation Text: <S sid ="326" ssid = "279">Gold standards, however, 435 cannot be uniﬁed into a single standard (Fung and Wu 1994; Sproat et al. 1996).</S> | Reference Offset: ['410'] | Reference Text: <S sid ="410" ssid = "13">However, until such standards are universally adopted in evaluating Chinese segmenters, claims about performance in terms of simple measures like percent correct should be taken with a grain of salt; see, again, Wu and Fung (1994) for further arguments supporting this conclusion.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 23 | Reference Article: J96-3004.xml | Citing Article: J97-4004.xml | Citation Marker Offset: ['9'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['9'] | Citation Text: <S sid ="9" ssid = "9">Since in written Chinese there is no explicit word delimiter (equivalent to the blank space in written English), the problem of Chinese sentence tokenization has been the focus of considerable research efforts, and significant advancements have been made (e.g., Bai 1995; Zhang et al. 1994; Chen and Liu 1992; Chiang et al. 1992; Fan and Tsai 1988; Gan 1995; Gan, Palmer, and Lua 1996; Guo 1993; He, Xu, and Sun 1991; Huang 1989; Huang and Xia 1996; Jie 1989; Jie, Liu, and Liang 1991a, 1991b; Jin and Chen 1995; Lai et al. 1992; Li et al. 1995; Liang 1986, 1987, 1990; Liu 1986a, 1986b; Liu, Tan, and Shen 1994; Lua 1990, 1994, and 1995; Ma 1996; Nie, Jin, and Hannan 1994; Sproat and Shih 1990; Sproat et al. 1996;</S> | Reference Offset: ['21'] | Reference Text: <S sid ="21" ssid = "21">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion &quot;word&quot; has never played a role in Chinese philological tradition, and the idea that Chinese lacks any­ thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 25 | Reference Article: J96-3004.xml | Citing Article: J97-4004.xml | Citation Marker Offset: ['613'] | Citation Marker: 1996 | Citation Offset: ['612','613'] | Citation Text: <S sid ="612" ssid = "54">The weighted finite-state transducer model developed by Sproat et al.</S><S sid ="613" ssid = "55">(1996) is another excellent representative example.</S> | Reference Offset: ['153'] | Reference Text: <S sid ="153" ssid = "17">For example, it is well-known that one can build a finite-state bigram (word) model by simply assigning a state Si to each word Wi in the vocabulary, and having (word) arcs leaving that state weighted such that for each Wj and corresponding arc aj leaving Si, the cost on aj is the bigram cost of WiWj- (Costs for unseen bigrams in such a scheme would typically be modeled with a special backoff state.)</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 26 | Reference Article: J96-3004.xml | Citing Article: J97-4004.xml | Citation Marker Offset: ['621'] | Citation Marker: 1996 | Citation Offset: ['621','622'] | Citation Text: <S sid ="621" ssid = "63">While it may not be totally impossible to fully incorporate such knowledge and heuristics into the general framework of path evaluation and searching, they are apÂ­ parently employed neither in Sproat et al.</S><S sid ="622" ssid = "64">(1996) nor in Ma (1996).</S> | Reference Offset: ['80'] | Reference Text: <S sid ="80" ssid = "18">Finally, quite a few hanzi are homographs, meaning that they may be pronounced in several different ways, and in extreme cases apparently represent different morphemes: The prenominal modifi­ cation marker eg deO is presumably a different morpheme from the second morpheme of §eg mu4di4, even though they are written the same way.4 The second point, which will be relevant in the discussion of personal names in Section 4.4, relates to the internal structure of hanzi.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 27 | Reference Article: J96-3004.xml | Citing Article: N10-1068.xml | Citation Marker Offset: ['6'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['6'] | Citation Text: <S sid ="6" ssid = "6">Many natural language models can be captured by weighted finite-state transducers (Pereira et al., 1994; Sproat et al., 1996; Knight and AlOnaizan, 1998; Clark, 2002; Kolak et al., 2003; Mathias and Byrne, 2006), which offer several benefits:â€¢ WFSTs provide a uniform knowledge represen tation.</S> | Reference Offset: ['240'] | Reference Text: <S sid ="240" ssid = "104">G1 and G2 are hanzi, we can estimate the probability of the sequence being a name as the product of: • the probability that a word chosen randomly from a text will be a name-p(rule 1), and • the probability that the name is of the form 1hanzi-family 2hanzi-given-p(rule 2), and • the probability that the family name is the particular hanzi F1-p(rule 6), and • the probability that the given name consists of the particular hanzi G1 and G2-p(rule 9) This model is essentially the one proposed in Chang et al.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 28 | Reference Article: J96-3004.xml | Citing Article: P03-1035.xml | Citation Marker Offset: ['41'] | Citation Marker: 1996 | Citation Offset: ['41','42'] | Citation Text: <S sid ="41" ssid = "18">One example of such approaches is Sproat et al.</S><S sid ="42" ssid = "19">(1996), which is based on weighted finite-state transducers (FSTs).</S> | Reference Offset: ['153'] | Reference Text: <S sid ="153" ssid = "17">For example, it is well-known that one can build a finite-state bigram (word) model by simply assigning a state Si to each word Wi in the vocabulary, and having (word) arcs leaving that state weighted such that for each Wj and corresponding arc aj leaving Si, the cost on aj is the bigram cost of WiWj- (Costs for unseen bigrams in such a scheme would typically be modeled with a special backoff state.)</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 29 | Reference Article: J96-3004.xml | Citing Article: P03-1035.xml | Citation Marker Offset: ['122'] | Citation Marker: 1996 | Citation Offset: ['122'] | Citation Text: <S sid ="122" ssid = "27">Because any character strings can be in principle named entities of one or more types, to limit the number of candidates for a more effective search, we generate named entity candidates, given an input string, in two steps: First, for each type, we use a set of constraints (which are compiled by 3 Sproat et al.</S> | Reference Offset: ['172'] | Reference Text: <S sid ="172" ssid = "36">Clearly this is not the only way to estimate word-frequencies, however, and one could consider applying other methods: in partic­ ular since the problem is similar to the problem of assigning part-of-speech tags to an untagged corpus given a lexicon and some initial estimate of the a priori probabilities for the tags, one might consider a more sophisticated approach such as that described in Kupiec (1992); one could also use methods that depend on a small hand-tagged seed corpus, as suggested by one reviewer.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 30 | Reference Article: J96-3004.xml | Citing Article: P03-1035.xml | Citation Marker Offset: ['155'] | Citation Marker: 1996 | Citation Offset: ['154','155'] | Citation Text: <S sid ="154" ssid = "59">5.2.4 Transliterations of foreign names As described in Sproat et al.</S><S sid ="155" ssid = "60">(1996): FNs are usually transliterated using Chinese character strings whose sequential pronunciation mimics the source language pronunciation of the name.</S> | Reference Offset: ['281'] | Reference Text: <S sid ="281" ssid = "145">Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 31 | Reference Article: J96-3004.xml | Citing Article: P06-1010.xml | Citation Marker Offset: ['43'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['42','43'] | Citation Text: <S sid ="42" ssid = "10">Candidate Chinese transliterations are generated by consulting a list of characters that are frequently used for transliterating foreign names.</S><S sid ="43" ssid = "11">As discussed elsewhere (Sproat et al., 1996), a subset of a few hundred characters (out of several thousand) tends to be used overwhelmingly for transliterating foreign names into Chinese.</S> | Reference Offset: ['240'] | Reference Text: <S sid ="240" ssid = "104">G1 and G2 are hanzi, we can estimate the probability of the sequence being a name as the product of: • the probability that a word chosen randomly from a text will be a name-p(rule 1), and • the probability that the name is of the form 1hanzi-family 2hanzi-given-p(rule 2), and • the probability that the family name is the particular hanzi F1-p(rule 6), and • the probability that the given name consists of the particular hanzi G1 and G2-p(rule 9) This model is essentially the one proposed in Chang et al.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 32 | Reference Article: J96-3004.xml | Citing Article: P06-1126.xml | Citation Marker Offset: ['7'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['7'] | Citation Text: <S sid ="7" ssid = "7">Chinese word segmentation is the initial stage of many Chinese language processing tasks, and has received a lot of attention in the literature (Sproat et al., 1996; Sun and Tsou, 2001; Zhang et al., 2003; Peng et al., 2004).</S> | Reference Offset: ['21'] | Reference Text: <S sid ="21" ssid = "21">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion &quot;word&quot; has never played a role in Chinese philological tradition, and the idea that Chinese lacks any­ thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 33 | Reference Article: J96-3004.xml | Citing Article: P07-1015.xml | Citation Marker Offset: ['113'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['113'] | Citation Text: <S sid ="113" ssid = "21">Using the 495 characters that are frequently used for transliterating foreign names (Sproat et al., 1996), a sequence of three of more characters from the list was taken as a possible candidate for Chinese.</S> | Reference Offset: ['240'] | Reference Text: <S sid ="240" ssid = "104">G1 and G2 are hanzi, we can estimate the probability of the sequence being a name as the product of: • the probability that a word chosen randomly from a text will be a name-p(rule 1), and • the probability that the name is of the form 1hanzi-family 2hanzi-given-p(rule 2), and • the probability that the family name is the particular hanzi F1-p(rule 6), and • the probability that the given name consists of the particular hanzi G1 and G2-p(rule 9) This model is essentially the one proposed in Chang et al.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 34 | Reference Article: J96-3004.xml | Citing Article: P07-1016.xml | Citation Marker Offset: ['70'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['70'] | Citation Text: <S sid ="70" ssid = "42">As discussed elsewhere (Sproat et al., 1996), out of several thousand common Chinese characters, a subset of a few hundred characters tends to be used overwhelmingly for transliterating English names to Chinese, e.g. only 731 Chinese characters are adopted in the E-C corpus.</S> | Reference Offset: ['170'] | Reference Text: <S sid ="170" ssid = "34">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 35 | Reference Article: J96-3004.xml | Citing Article: P12-1110.xml | Citation Marker Offset: ['105'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['105'] | Citation Text: <S sid ="105" ssid = "53">3.3.1 Dictionary features Because segmentation using a dictionary alone can serve as a strong baseline in Chinese word segmentation (Sproat et al., 1996), the use of dictionaries is expected to make our joint model more robust and enables us to investigate the contribution of the syntactic dependency in a more realistic setting.</S> | Reference Offset: ['240'] | Reference Text: <S sid ="240" ssid = "104">G1 and G2 are hanzi, we can estimate the probability of the sequence being a name as the product of: • the probability that a word chosen randomly from a text will be a name-p(rule 1), and • the probability that the name is of the form 1hanzi-family 2hanzi-given-p(rule 2), and • the probability that the family name is the particular hanzi F1-p(rule 6), and • the probability that the given name consists of the particular hanzi G1 and G2-p(rule 9) This model is essentially the one proposed in Chang et al.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 36 | Reference Article: J96-3004.xml | Citing Article: P12-1111.xml | Citation Marker Offset: ['91'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['91'] | Citation Text: <S sid ="91" ssid = "31">In early work, rule-based models find words one by one based on heuristics such as forward maximum match (Sproat et al., 1996).</S> | Reference Offset: ['166'] | Reference Text: <S sid ="166" ssid = "30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 37 | Reference Article: J96-3004.xml | Citing Article: P97-1041.xml | Citation Marker Offset: ['12'] | Citation Marker: 1996 | Citation Offset: ['12'] | Citation Text: <S sid ="12" ssid = "12">For a discussion of recent Chinese segmentation work, see Sproat et al. {1996).</S> | Reference Offset: ['21'] | Reference Text: <S sid ="21" ssid = "21">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion &quot;word&quot; has never played a role in Chinese philological tradition, and the idea that Chinese lacks any­ thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 38 | Reference Article: J96-3004.xml | Citing Article: P98-1076.xml | Citation Marker Offset: ['145'] | Citation Marker: 1996 | Citation Offset: ['144','145'] | Citation Text: <S sid ="144" ssid = "11">The actual implementation of the weighted finiteÂ­ state transducer by Sproat et al.</S><S sid ="145" ssid = "12">(1996) can be taken as an evidence that the hypothesis of one tokenization per source has already in practical use.</S> | Reference Offset: ['240'] | Reference Text: <S sid ="240" ssid = "104">G1 and G2 are hanzi, we can estimate the probability of the sequence being a name as the product of: • the probability that a word chosen randomly from a text will be a name-p(rule 1), and • the probability that the name is of the form 1hanzi-family 2hanzi-given-p(rule 2), and • the probability that the family name is the particular hanzi F1-p(rule 6), and • the probability that the given name consists of the particular hanzi G1 and G2-p(rule 9) This model is essentially the one proposed in Chang et al.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 39 | Reference Article: J96-3004.xml | Citing Article: P98-1076.xml | Citation Marker Offset: ['150'] | Citation Marker: 1996 | Citation Offset: ['149','150'] | Citation Text: <S sid ="149" ssid = "2">utilizing local and sentential constraints, what Sproat et al.</S><S sid ="150" ssid = "3">( 1996) implemented was simply a token unigram scoring function.</S> | Reference Offset: ['240'] | Reference Text: <S sid ="240" ssid = "104">G1 and G2 are hanzi, we can estimate the probability of the sequence being a name as the product of: • the probability that a word chosen randomly from a text will be a name-p(rule 1), and • the probability that the name is of the form 1hanzi-family 2hanzi-given-p(rule 2), and • the probability that the family name is the particular hanzi F1-p(rule 6), and • the probability that the given name consists of the particular hanzi G1 and G2-p(rule 9) This model is essentially the one proposed in Chang et al.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 40 | Reference Article: J96-3004.xml | Citing Article: P99-1036.xml | Citation Marker Offset: ['6'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['5','6'] | Citation Text: <S sid ="5" ssid = "5">In Japanese, around 95% word segmentation acÂ­ curacy is reported by using a word-based lanÂ­ guage model and the Viterbi-like dynamic programÂ­ ming procedures (Nagata, 1994; Yamamoto, 1996; Takeuchi and Matsumoto, 1997; Haruno and MatÂ­ sumoto, 1997).</S><S sid ="6" ssid = "6">About the same accuracy is reported in Chinese by statistical methods (Sproat et al., 1996).</S> | Reference Offset: ['21'] | Reference Text: <S sid ="21" ssid = "21">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion &quot;word&quot; has never played a role in Chinese philological tradition, and the idea that Chinese lacks any­ thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 41 | Reference Article: J96-3004.xml | Citing Article: P99-1036.xml | Citation Marker Offset: ['8'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['8'] | Citation Text: <S sid ="8" ssid = "8">There are two approaches to solve this problem: to increase the coverage of the dictionary (Fung and Wu, 1994; Chang et al., 1995; Mori and Nagao, 1996) and to design a better model for unknown words (Nagata, 1996; Sproat et al., 1996).</S> | Reference Offset: ['54'] | Reference Text: <S sid ="54" ssid = "15">A minimal requirement for building a Chinese word segmenter is obviously a dictionary; furthermore, as has been argued persuasively by Fung and Wu (1994), one will perform much better at segmenting text by using a dictionary constructed with text of the same genre as the text to be segmented.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 42 | Reference Article: J96-3004.xml | Citing Article: P99-1036.xml | Citation Marker Offset: ['10'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['10'] | Citation Text: <S sid ="10" ssid = "10">To improve word segmentaÂ­ tion accuracy, (Nagata, 1996) used a single general purpose unknown word model, while (Sproat et al., 1996) used a set of specific word models such as for plurals, personal names, and transliterated foreign words.</S> | Reference Offset: ['170'] | Reference Text: <S sid ="170" ssid = "34">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 43 | Reference Article: J96-3004.xml | Citing Article: P99-1036.xml | Citation Marker Offset: ['178'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['178'] | Citation Text: <S sid ="178" ssid = "108">Word segmentation accuracy is expressed in terms of recall and precision as is done in the previous research (Sproat et al., 1996).</S> | Reference Offset: ['128'] | Reference Text: <S sid ="128" ssid = "66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 44 | Reference Article: J96-3004.xml | Citing Article: W00-0803.xml | Citation Marker Offset: ['29'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['29'] | Citation Text: <S sid ="29" ssid = "29">Segmentation rutd morphological analysis related issues of both Chinese and Japanese are intensively addressed elsewhere (Sproat et al., 1996; MatsUIIt(ltO et al., 1997 and many others).</S> | Reference Offset: ['244'] | Reference Text: <S sid ="244" ssid = "108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.&apos;s Model.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 45 | Reference Article: J96-3004.xml | Citing Article: W00-1207.xml | Citation Marker Offset: ['10'] | Citation Marker: Sproat et al 1996 | Citation Offset: ['10'] | Citation Text: <S sid ="10" ssid = "10">Purely statistical methods of word segmentation (e.g. de Marcken 1996, Sproat et al 1996, Tung and Lee 1994, Lin et al (1993), Chiang et al (1992), Lua, Huang et al, etc.) often fail to identify those words because of the sparse data problem, as the likelihood for those words to appear in the training texts is extremely low.</S> | Reference Offset: ['125'] | Reference Text: <S sid ="125" ssid = "63">Some of these approaches (e.g., Lin, Chiang, and Su [1993]) attempt to identify unknown words, but do not ac­ tually tag the words as belonging to one or another class of expression.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 46 | Reference Article: J96-3004.xml | Citing Article: W01-0513.xml | Citation Marker Offset: ['41'] | Citation Marker: Sproat, et al, 1996 | Citation Offset: ['40','41'] | Citation Text: <S sid ="40" ssid = "11">The principal work on segmentation has focused either on identifying words in phonetic streams (Saffran, et.</S><S sid ="41" ssid = "12">al, 1996; Brent, 1996; de Marcken, 1996) or on tokenizing Asian and Indian languages that do not normally include word delimiters in their orthography (Sproat, et al, 1996; Ponte and Croft 1996; Shimohata, 1997; Teahan, et al., 2000; and many others).</S> | Reference Offset: ['20'] | Reference Text: <S sid ="20" ssid = "20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ­ ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 47 | Reference Article: J96-3004.xml | Citing Article: W02-1117.xml | Citation Marker Offset: ['13'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['13'] | Citation Text: <S sid ="13" ssid = "13">For examples: these words should be obtained: The ambiguous string is .There are some methods to resolve this problem: the one is the method forward maximum matching, backward maximum matching and minimum matching are used to find out the possible word strings from the character string [Guo 1997; Sproat et al. 1996; Gu and Mao 1994; Li et al. 1991; Wang et al. 1991b; Wang et al. 1990].</S> | Reference Offset: ['123'] | Reference Text: <S sid ="123" ssid = "61">Statistical methods seem particularly applicable to the problem of unknown-word identification, especially for constructions like names, where the linguistic constraints are minimal, and where one therefore wants to know not only that a particular se­ quence of hanzi might be a name, but that it is likely to be a name with some probabil­ ity.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 48 | Reference Article: J96-3004.xml | Citing Article: W02-1808.xml | Citation Marker Offset: ['5'] | Citation Marker: 1996 | Citation Offset: ['5'] | Citation Text: <S sid ="5" ssid = "5">Statistical approaches involve language mod els mostly finite-state ones trained on some large-scale corpora as showed in Fan and Tsai (1988) Chang et al (1991) Chiang et al (1992) Sproat et al (1996)</S> | Reference Offset: ['242'] | Reference Text: <S sid ="242" ssid = "106">The first probability is estimated from a name count in a text database, and the rest of the probabilities are estimated from a large list of personal names.n Note that in Chang et al.&apos;s model the p(rule 9) is estimated as the product of the probability of finding G 1 in the first position of a two-hanzi given name and the probability of finding G2 in the second position of a two-hanzi given name, and we use essentially the same estimate here, with some modifications as described later on.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 49 | Reference Article: J96-3004.xml | Citing Article: W03-1025.xml | Citation Marker Offset: ['17'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['17'] | Citation Text: <S sid ="17" ssid = "17">There are multiple studies (Wu and Fung, 1994; Sproat et al., 1996; Luo and Roukos, 1996) showing that the agreement between two (untrained) native speakers is about upper to lower</S> | Reference Offset: ['325'] | Reference Text: <S sid ="325" ssid = "34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement.15 One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix, computing a classical metric multidimensional scaling (Torgerson 1958; Becker, Chambers, Wilks 1988) on that dis­ tance matrix, and plotting the first two most significant dimensions.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 50 | Reference Article: J96-3004.xml | Citing Article: W03-1025.xml | Citation Marker Offset: ['180'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['180'] | Citation Text: <S sid ="180" ssid = "4">Chinese word segmentation is a well-known problem that has been studied extensively (Wu and Fung, 1994; Sproat et al., 1996; Luo and Roukos, 1996) and it is known that human agreement is relatively low.</S> | Reference Offset: ['54'] | Reference Text: <S sid ="54" ssid = "15">A minimal requirement for building a Chinese word segmenter is obviously a dictionary; furthermore, as has been argued persuasively by Fung and Wu (1994), one will perform much better at segmenting text by using a dictionary constructed with text of the same genre as the text to be segmented.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 51 | Reference Article: J96-3004.xml | Citing Article: W03-1025.xml | Citation Marker Offset: ['187'] | Citation Marker: 1996 | Citation Offset: ['186','187'] | Citation Text: <S sid ="186" ssid = "10">Sproat et al.</S><S sid ="187" ssid = "11">(1996) employs stochastic finite state machines to find word boundaries.</S> | Reference Offset: ['16'] | Reference Text: <S sid ="16" ssid = "16">com §Cambridge, UK Email: nc201@eng.cam.ac.uk © 1996 Association for Computational Linguistics (a) B ) ( , : &amp; ; ? &apos; H o w d o y o u s a y o c t o p u s i n J a p a n e s e ? &apos; (b) P l a u s i b l e S e g m e n t a t i o n I B X I I 1 : &amp; I 0 0 r i 4 w e n 2 z h a n g l y u 2 z e n 3 m e 0 s h u o l &apos; J a p a n e s e &apos; &apos; o c t o p u s &apos; &apos; h o w &apos; &apos; s a y &apos; (c) Figure 1 I m p l a u s i b l e S e g m e n t a t i o n [§] lxI 1:&amp;I ri4 wen2 zhangl yu2zen3 me0 shuol &apos;Japan&apos; &apos;essay&apos; &apos;fish&apos; &apos;how&apos; &apos;say&apos; A Chinese sentence in (a) illustrating the lack of word boundaries.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 52 | Reference Article: J96-3004.xml | Citing Article: W03-1728.xml | Citation Marker Offset: ['3'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['3'] | Citation Text: <S sid ="3" ssid = "3">This may sound simple enough but in reality identifying words in Chinese is a nontrivial problem that has drawn a large body of research in the Chinese language processing community (Fan and Tsai, 1988; Gan et al., 1996; Sproat et al., 1996; Wu, 2003; Xue, 2003).</S> | Reference Offset: ['21'] | Reference Text: <S sid ="21" ssid = "21">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion &quot;word&quot; has never played a role in Chinese philological tradition, and the idea that Chinese lacks any­ thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 53 | Reference Article: J96-3004.xml | Citing Article: W05-0709.xml | Citation Marker Offset: ['83'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['83'] | Citation Text: <S sid ="83" ssid = "9">In addition to the model based upon a dictionary of stems and words, we also experimented with models based upon character n-grams, similar to those used for Chinese segmentation (Sproat et al., 1996).</S> | Reference Offset: ['328'] | Reference Text: <S sid ="328" ssid = "37">In addition to the automatic methods, AG, GR, and ST, just discussed, we also added to the plot the values for the current algorithm using only dictionary entries (i.e., no productively derived words or names).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 54 | Reference Article: J96-3004.xml | Citing Article: W06-1630.xml | Citation Marker Offset: ['118'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['118'] | Citation Text: <S sid ="118" ssid = "13">The words were stemmed all possible ways using simple hand-developed affix lists: for example, given a Hindi word c1 c2 c3 , if both c3 and c2 c3 are in our suffix and ending list, then this single word generates three possible candidates: c1 , c1 c2 , and c1c2 c3 . In contrast, Chinese candidates were extracted using a list of 495 characters that are frequently used for foreign names (Sproat et al., 1996).</S> | Reference Offset: ['170'] | Reference Text: <S sid ="170" ssid = "34">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 55 | Reference Article: J96-3004.xml | Citing Article: W10-3212.xml | Citation Marker Offset: ['16'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['16'] | Citation Text: <S sid ="16" ssid = "2">In such languages, words are segmented using more advanced techniques, which can be categorized into three methods: (i) Dictionary/lexicon based approaches (ii) Linguistic knowledge based approaches (iii) Machine learning based approaches/statistical approaches (Haruechaiyasak et al., 2008) Longest matching (Poowarawan, 1986; Richard Sproat, 1996) and maximum matching (Sproat et al., 1996; Haizhou &amp; Baosheng, 1998) are examples of lexicon based approaches.</S> | Reference Offset: ['370'] | Reference Text: <S sid ="370" ssid = "79">In these examples, the names identified by the two systems (if any) are underlined; the sentence with the correct segmentation is boxed.19 The differences in performance between the two systems relate directly to three issues, which can be seen as differences in the tuning of the models, rather than repre­ senting differences in the capabilities of the model per se.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 56 | Reference Article: J96-3004.xml | Citing Article: W10-3708.xml | Citation Marker Offset: ['16'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['16'] | Citation Text: <S sid ="16" ssid = "16">Experiments have shown only about 75% agreement among native speakers regarding the correct word segmentation (Sproat et al., 1996).</S> | Reference Offset: ['325'] | Reference Text: <S sid ="325" ssid = "34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement.15 One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix, computing a classical metric multidimensional scaling (Torgerson 1958; Becker, Chambers, Wilks 1988) on that dis­ tance matrix, and plotting the first two most significant dimensions.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 57 | Reference Article: J96-3004.xml | Citing Article: W11-0823.xml | Citation Marker Offset: ['174'] | Citation Marker: 1996 | Citation Offset: ['174'] | Citation Text: <S sid ="174" ssid = "7">There are a number of popular dictionary-based solutions such as Cha Sen10 and Juman.11 Sproat et al (1996) proposed an alternative solution based on distributional statistics such as mutual information.</S> | Reference Offset: ['240'] | Reference Text: <S sid ="240" ssid = "104">G1 and G2 are hanzi, we can estimate the probability of the sequence being a name as the product of: • the probability that a word chosen randomly from a text will be a name-p(rule 1), and • the probability that the name is of the form 1hanzi-family 2hanzi-given-p(rule 2), and • the probability that the family name is the particular hanzi F1-p(rule 6), and • the probability that the given name consists of the particular hanzi G1 and G2-p(rule 9) This model is essentially the one proposed in Chang et al.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 58 | Reference Article: J96-3004.xml | Citing Article: W12-1011.xml | Citation Marker Offset: ['41'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['41'] | Citation Text: <S sid ="41" ssid = "5">Indeed, even native speakers can agree on word boundaries in modern Chinese only about 76% of the time (Sproat et al., 1996).</S> | Reference Offset: ['16'] | Reference Text: <S sid ="16" ssid = "16">com §Cambridge, UK Email: nc201@eng.cam.ac.uk © 1996 Association for Computational Linguistics (a) B ) ( , : &amp; ; ? &apos; H o w d o y o u s a y o c t o p u s i n J a p a n e s e ? &apos; (b) P l a u s i b l e S e g m e n t a t i o n I B X I I 1 : &amp; I 0 0 r i 4 w e n 2 z h a n g l y u 2 z e n 3 m e 0 s h u o l &apos; J a p a n e s e &apos; &apos; o c t o p u s &apos; &apos; h o w &apos; &apos; s a y &apos; (c) Figure 1 I m p l a u s i b l e S e g m e n t a t i o n [§] lxI 1:&amp;I ri4 wen2 zhangl yu2zen3 me0 shuol &apos;Japan&apos; &apos;essay&apos; &apos;fish&apos; &apos;how&apos; &apos;say&apos; A Chinese sentence in (a) illustrating the lack of word boundaries.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 59 | Reference Article: J96-3004.xml | Citing Article: W12-1011.xml | Citation Marker Offset: ['204'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['204'] | Citation Text: <S sid ="204" ssid = "9">No comparable figure has been reported for classical Chinese word segmentation, but this rate compares favorably with past attempts for modern Chinese, e.g., an average of 76% inter- human agreement rate in (Sproat et al., 1996).</S> | Reference Offset: ['21'] | Reference Text: <S sid ="21" ssid = "21">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion &quot;word&quot; has never played a role in Chinese philological tradition, and the idea that Chinese lacks any­ thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 60 | Reference Article: J96-3004.xml | Citing Article: W12-2303.xml | Citation Marker Offset: ['12'] | Citation Marker: 1996 | Citation Offset: ['11','12'] | Citation Text: <S sid ="11" ssid = "11">An extension of this approach is the dynamic programming search of the most probable word combination on the word lattice, such as Ma (1996) and Sproat et al.</S><S sid ="12" ssid = "12">(1996), which utilize information such as word frequency statistics in a corpus to build the model and are less efficient but more accurate.</S> | Reference Offset: ['172'] | Reference Text: <S sid ="172" ssid = "36">Clearly this is not the only way to estimate word-frequencies, however, and one could consider applying other methods: in partic­ ular since the problem is similar to the problem of assigning part-of-speech tags to an untagged corpus given a lexicon and some initial estimate of the a priori probabilities for the tags, one might consider a more sophisticated approach such as that described in Kupiec (1992); one could also use methods that depend on a small hand-tagged seed corpus, as suggested by one reviewer.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 61 | Reference Article: J96-3004.xml | Citing Article: W12-2303.xml | Citation Marker Offset: ['157'] | Citation Marker: 1996 | Citation Offset: ['155','156','157'] | Citation Text: <S sid ="155" ssid = "30">There are many other OOV recognition methods proposed in literature before the rise of machine learning in the field.</S><S sid ="156" ssid = "31">For example, the Sproat et al.</S><S sid ="157" ssid = "32">(1996) system can successfully recognize OOVs of strong patterns, such as Chinese personal names, transliterations, using finite-state techniques.</S> | Reference Offset: ['240'] | Reference Text: <S sid ="240" ssid = "104">G1 and G2 are hanzi, we can estimate the probability of the sequence being a name as the product of: • the probability that a word chosen randomly from a text will be a name-p(rule 1), and • the probability that the name is of the form 1hanzi-family 2hanzi-given-p(rule 2), and • the probability that the family name is the particular hanzi F1-p(rule 6), and • the probability that the given name consists of the particular hanzi G1 and G2-p(rule 9) This model is essentially the one proposed in Chang et al.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 62 | Reference Article: J96-3004.xml | Citing Article: W97-0120.xml | Citation Marker Offset: ['26'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['26'] | Citation Text: <S sid ="26" ssid = "26">One of the major problems in unsupervised word segmentation is the treatment of unseen word [Sproat et al., 1996] wrote lexical rules for each productive morphological process, such as plur noun formation, Chinese personal names, and transliterations of foreign words.</S> | Reference Offset: ['283'] | Reference Text: <S sid ="283" ssid = "147">Fortunately, there are only a few hundred hanzi that are particularly common in transliterations; indeed, the commonest ones, such as E. bal, m er3, and iij al are often clear indicators that a sequence of hanzi containing them is foreign: even a name like !:i*m xia4mi3-er3 &apos;Shamir,&apos; which is a legal Chi­ nese personal name, retains a foreign flavor because of liM.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 63 | Reference Article: J96-3004.xml | Citing Article: W97-0120.xml | Citation Marker Offset: ['69'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['69'] | Citation Text: <S sid ="69" ssid = "5">We used a simple greedy algorithm described in [Sproat et al., 1996].</S> | Reference Offset: ['242'] | Reference Text: <S sid ="242" ssid = "106">The first probability is estimated from a name count in a text database, and the rest of the probabilities are estimated from a large list of personal names.n Note that in Chang et al.&apos;s model the p(rule 9) is estimated as the product of the probability of finding G 1 in the first position of a two-hanzi given name and the probability of finding G2 in the second position of a two-hanzi given name, and we use essentially the same estimate here, with some modifications as described later on.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 64 | Reference Article: J96-3004.xml | Citing Article: W97-0120.xml | Citation Marker Offset: ['73'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['73'] | Citation Text: <S sid ="73" ssid = "9">[Sproat et al., 1996] also proposed another method to estimate a set of initial word frequencies without segmenting the corpus.</S> | Reference Offset: ['170'] | Reference Text: <S sid ="170" ssid = "34">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 65 | Reference Article: J96-3004.xml | Citing Article: W97-0120.xml | Citation Marker Offset: ['86'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['86'] | Citation Text: <S sid ="86" ssid = "22">The problem of the longest match string frequency method is that if a word W1 is a substring of other word w2 and if wl always appears as a substring of w2 in the training text, just like m 1Although (Sproat et al., 1996] calls it &quot;maximum matching&quot;, we call this method &quot;longest match&quot; according to a review on Chinese word segmentation [Wu and Tseng, 1993) and the literal translation of the Japanese name of the method Hi!:.</S> | Reference Offset: ['21'] | Reference Text: <S sid ="21" ssid = "21">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion &quot;word&quot; has never played a role in Chinese philological tradition, and the idea that Chinese lacks any­ thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 66 | Reference Article: J96-3004.xml | Citing Article: W97-0120.xml | Citation Marker Offset: ['121'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['121'] | Citation Text: <S sid ="121" ssid = "15">Word Segmentation accuracy is expressed in terms of recall and precision as is done for bracketing of partial parses [Nagata, 1994, Sproat et al., 1996).</S> | Reference Offset: ['128'] | Reference Text: <S sid ="128" ssid = "66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 67 | Reference Article: J96-3004.xml | Citing Article: W97-0316.xml | Citation Marker Offset: ['11'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['10','11'] | Citation Text: <S sid ="10" ssid = "10">Automatic methods for correctly isolating words in a sentence -- a process called word segmentation -- is therefore an important and necessary first step to be taken before other analysis can begin.</S><S sid ="11" ssid = "11">Many researchers have proposed practical methods to resolve this problem such as (Nie et al., 1995, Wu and Tsang, 1995, Jin &amp; Chen, 1996, Ponte &amp; Croft, 1996, Sproat et al., 1996, Sun et al., 1997).</S> | Reference Offset: ['172'] | Reference Text: <S sid ="172" ssid = "36">Clearly this is not the only way to estimate word-frequencies, however, and one could consider applying other methods: in partic­ ular since the problem is similar to the problem of assigning part-of-speech tags to an untagged corpus given a lexicon and some initial estimate of the a priori probabilities for the tags, one might consider a more sophisticated approach such as that described in Kupiec (1992); one could also use methods that depend on a small hand-tagged seed corpus, as suggested by one reviewer.</S> | Discourse Facet: BLANK | Annotator: Predictions

