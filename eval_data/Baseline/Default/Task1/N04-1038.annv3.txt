Citance Number: 1 | Reference Article: N04-1038.txt | Citing Article: E12-1054.txt | Citation Marker Offset: ['7'] | Citation Marker: Bean and Riloff, 2004 | Citation Offset: ['7'] | Citation Text: <S sid ="7" ssid = "7">Measuring the contextual fitness of a term in its context is a key component in different NLP applications like speech recognition (Inkpen and DeÂ´silets, 2005), optical character recognition (Wick et al., 2007), co-reference resolution (Bean and Riloff, 2004)</S> | Reference Offset: ['241'] | Reference Text: <S sid ="241" ssid = "179">However their work did not consider other types of lexical expectations (e.g., PP arguments), semantic expectations, or context comparisons like our case- frame network.(Niyu et al., 1998) used unsupervised learning to ac quire gender, number, and animacy information from resolutions produced by a statistical pronoun resolver.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 2 | Reference Article: N04-1038.txt | Citing Article: H05-1003.txt | Citation Marker Offset: ['35'] | Citation Marker: 2004 | Citation Offset: ['35','36'] | Citation Text: <S sid ="35" ssid = "11">Recently Bean and Riloff (2004) have sought to acquire automatically some semantic patterns that can be used as contextual information to improve reference resolution, using techniques adapted from information extraction.</S><S sid ="36" ssid = "12">Their experiments were conducted on collections of texts in two topic areas (terrorism and natural disasters).</S> | Reference Offset: ['82'] | Reference Text: <S sid ="82" ssid = "20">For example, the passive voice pattern “&lt;subject&gt; were kidnapped” and the active voice pattern “kidnapped &lt;direct object&gt;” are merged into a single normalized pattern “kidnapped &lt;patient&gt;”.2 For the sake of sim plicity, we will refer to these normalized extraction patterns as caseframes.3 These caseframes can capture two types of contextual role information: (1) thematic roles corresponding to events (e.g, “&lt;agent&gt; kidnapped” or “kidnapped &lt;patient&gt;”), and (2) predicate-argument relations associated with both verbs and nouns (e.g., “kidnapped for &lt;np&gt;” or “vehicle with &lt;np&gt;”).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 3 | Reference Article: N04-1038.txt | Citing Article: N13-1104.txt | Citation Marker Offset: ['109'] | Citation Marker: 2004 | Citation Offset: ['109'] | Citation Text: <S sid ="109" ssid = "5">the dependency from the event head to an event argument depi,j , our model instead emits the pair of event head and dependency relation, which we call a caseframe following Bean and Riloff (2004).</S> | Reference Offset: ['49'] | Reference Text: <S sid ="49" ssid = "20">Using this heuristic, BABAR identifies existential definite NPs in the training corpus using our previous learning algorithm (Bean and Riloff, 1999) and resolves all occurrences of the same existential NP with each another.1 2.1.2 Syntactic Seeding BABAR also uses syntactic heuristics to identify anaphors and antecedents that can be easily resolved.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 4 | Reference Article: N04-1038.txt | Citing Article: N13-1110.txt | Citation Marker Offset: ['207'] | Citation Marker: 2004 | Citation Offset: ['207','208','209'] | Citation Text: <S sid ="207" ssid = "10">Another source of inspiration is the work by Bean and Riloff (2004).</S><S sid ="208" ssid = "11">They use contextual roles (i.e., the role that an NP plays in an event) for extracting patterns that can be used in coreference resolution, showing the relevance of verbs in deciding on coreference between their arguments.</S><S sid ="209" ssid = "12">However, they use a very small corpus (two domains) and do not aim to build a dictionary.</S> | Reference Offset: ['82'] | Reference Text: <S sid ="82" ssid = "20">For example, the passive voice pattern “&lt;subject&gt; were kidnapped” and the active voice pattern “kidnapped &lt;direct object&gt;” are merged into a single normalized pattern “kidnapped &lt;patient&gt;”.2 For the sake of sim plicity, we will refer to these normalized extraction patterns as caseframes.3 These caseframes can capture two types of contextual role information: (1) thematic roles corresponding to events (e.g, “&lt;agent&gt; kidnapped” or “kidnapped &lt;patient&gt;”), and (2) predicate-argument relations associated with both verbs and nouns (e.g., “kidnapped for &lt;np&gt;” or “vehicle with &lt;np&gt;”).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 5 | Reference Article: N04-1038.txt | Citing Article: P05-1020.txt | Citation Marker Offset: ['202'] | Citation Marker: 2004 | Citation Offset: ['202'] | Citation Text: <S sid ="202" ssid = "71">(2001)) and unsupervised approaches (e.g., Cardie and Wagstaff (1999), Bean and Riloff (2004)).</S> | Reference Offset: ['6'] | Reference Text: <S sid ="6" ssid = "6">The problem of coreference resolution has received considerable attention, including theoretical discourse models (e.g., (Grosz et al., 1995; Grosz and Sidner, 1998)), syntactic algorithms (e.g., (Hobbs, 1978; Lappin and Le- ass, 1994)), and supervised machine learning systems (Aone and Bennett, 1995; McCarthy and Lehnert, 1995; Ng and Cardie, 2002; Soon et al., 2001).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 6 | Reference Article: N04-1038.txt | Citing Article: P06-1005.txt | Citation Marker Offset: ['124'] | Citation Marker: Bean and Riloff, 2004 | Citation Offset: ['124'] | Citation Text: <S sid ="124" ssid = "9">Since no such corpus exists, researchers have used coarser features learned from smaller sets through supervised learning (Soon et al., 2001; Ng and Cardie, 2002), manually-defined coreference patterns to mine specific kinds of data (Bean and Riloff, 2004; Bergsma, 2005)</S> | Reference Offset: ['245'] | Reference Text: <S sid ="245" ssid = "183">Several coreference resolvers have used supervised learning techniques, such as decision trees and rule learners (Aone and Bennett, 1995; McCarthy and Lehnert, 1995; Ng and Cardie, 2002; Soon et al., 2001).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 7 | Reference Article: N04-1038.txt | Citing Article: P06-1005.txt | Citation Marker Offset: ['177'] | Citation Marker: 2004 | Citation Offset: ['177','178','179'] | Citation Text: <S sid ="177" ssid = "62">Bean and Riloff (2004) used bootstrapping to extend their semantic compatibility model, which they called contextual-role knowledge, by identifying certain cases of easily-resolved anaphors and antecedents.</S><S sid ="178" ssid = "63">They give the example â€œMr.</S><S sid ="179" ssid = "64">Bush disclosed the policy by reading it.â€ Once we identify that it and policy are coreferent, we include read:obj:policy as part of the compatibility model.</S> | Reference Offset: ['49'] | Reference Text: <S sid ="49" ssid = "20">Using this heuristic, BABAR identifies existential definite NPs in the training corpus using our previous learning algorithm (Bean and Riloff, 1999) and resolves all occurrences of the same existential NP with each another.1 2.1.2 Syntactic Seeding BABAR also uses syntactic heuristics to identify anaphors and antecedents that can be easily resolved.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 8 | Reference Article: N04-1038.txt | Citing Article: P07-1067.txt | Citation Marker Offset: ['46'] | Citation Marker: 2004 | Citation Offset: ['46','47','48','49'] | Citation Text: <S sid ="46" ssid = "9">Bean and Riloff (2004) present a system called BABAR that uses contextual role knowledge to do coreference resolution.</S><S sid ="47" ssid = "10">They apply an IE component to unannotated texts to generate a set of extraction caseframes.</S><S sid ="48" ssid = "11">Each caseframe represents a linguistic expression and a syntactic position, e.g. â€œmurder of &lt;NP&gt;â€, â€œkilled &lt;patient&gt;â€.</S><S sid ="49" ssid = "12">From the case- frames, they derive different types of contextual role knowledge for resolution, for example, whether an anaphor and an antecedent candidate can be filled into co-occurring caseframes, or whether they are substitutable for each other in their caseframes.</S> | Reference Offset: ['82'] | Reference Text: <S sid ="82" ssid = "20">For example, the passive voice pattern “&lt;subject&gt; were kidnapped” and the active voice pattern “kidnapped &lt;direct object&gt;” are merged into a single normalized pattern “kidnapped &lt;patient&gt;”.2 For the sake of sim plicity, we will refer to these normalized extraction patterns as caseframes.3 These caseframes can capture two types of contextual role information: (1) thematic roles corresponding to events (e.g, “&lt;agent&gt; kidnapped” or “kidnapped &lt;patient&gt;”), and (2) predicate-argument relations associated with both verbs and nouns (e.g., “kidnapped for &lt;np&gt;” or “vehicle with &lt;np&gt;”).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 9 | Reference Article: N04-1038.txt | Citing Article: P07-1068.txt | Citation Marker Offset: ['11'] | Citation Marker: 2004 | Citation Offset: ['11'] | Citation Text: <S sid ="11" ssid = "11">(2004)) or Wikipedia (Ponzetto and Strube, 2006), and the contextual role played by an NP (see Bean and Riloff (2004)).</S> | Reference Offset: ['155'] | Reference Text: <S sid ="155" ssid = "93">First, a non-anaphoric NP classifier identifies definite noun phrases that are existential, using both syntactic rules and our learned existential NP recognizer (Bean and Riloff, 1999), and removes them from the resolution process.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 10 | Reference Article: N04-1038.txt | Citing Article: P08-1090.txt | Citation Marker Offset: ['35'] | Citation Marker: 2004 | Citation Offset: ['35','38'] | Citation Text: <S sid ="35" ssid = "5">Bean and Riloff (2004) proposed the use of caseframe networks as a kind of contextual role knoweldge for anaphora resolution.</S><S sid ="38" ssid = "8">Bean and Riloff learn these networks from two topic-specific texts and apply them to the problem of anaphora resolution.</S> | Reference Offset: ['82'] | Reference Text: <S sid ="82" ssid = "20">For example, the passive voice pattern “&lt;subject&gt; were kidnapped” and the active voice pattern “kidnapped &lt;direct object&gt;” are merged into a single normalized pattern “kidnapped &lt;patient&gt;”.2 For the sake of sim plicity, we will refer to these normalized extraction patterns as caseframes.3 These caseframes can capture two types of contextual role information: (1) thematic roles corresponding to events (e.g, “&lt;agent&gt; kidnapped” or “kidnapped &lt;patient&gt;”), and (2) predicate-argument relations associated with both verbs and nouns (e.g., “kidnapped for &lt;np&gt;” or “vehicle with &lt;np&gt;”).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 11 | Reference Article: N04-1038.txt | Citing Article: P09-1068.txt | Citation Marker Offset: ['17'] | Citation Marker: Bean and Riloff, 2004 | Citation Offset: ['17'] | Citation Text: <S sid ="17" ssid = "17">In this paper we extend this work to represent sets of situation-specific events not unlike scripts, caseframes (Bean and Riloff, 2004)</S> | Reference Offset: ['82'] | Reference Text: <S sid ="82" ssid = "20">For example, the passive voice pattern “&lt;subject&gt; were kidnapped” and the active voice pattern “kidnapped &lt;direct object&gt;” are merged into a single normalized pattern “kidnapped &lt;patient&gt;”.2 For the sake of sim plicity, we will refer to these normalized extraction patterns as caseframes.3 These caseframes can capture two types of contextual role information: (1) thematic roles corresponding to events (e.g, “&lt;agent&gt; kidnapped” or “kidnapped &lt;patient&gt;”), and (2) predicate-argument relations associated with both verbs and nouns (e.g., “kidnapped for &lt;np&gt;” or “vehicle with &lt;np&gt;”).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 12 | Reference Article: N04-1038.txt | Citing Article: P09-1074.txt | Citation Marker Offset: ['223'] | Citation Marker: 2004 | Citation Offset: ['223'] | Citation Text: <S sid ="223" ssid = "160">Finally, several coreference systems have successfully incorporated anaphoricity determination modules (e.g. Ng and Cardie (2002a) and Bean and Riloff (2004)).</S> | Reference Offset: ['6'] | Reference Text: <S sid ="6" ssid = "6">The problem of coreference resolution has received considerable attention, including theoretical discourse models (e.g., (Grosz et al., 1995; Grosz and Sidner, 1998)), syntactic algorithms (e.g., (Hobbs, 1978; Lappin and Le- ass, 1994)), and supervised machine learning systems (Aone and Bennett, 1995; McCarthy and Lehnert, 1995; Ng and Cardie, 2002; Soon et al., 2001).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 13 | Reference Article: N04-1038.txt | Citing Article: P10-1142.txt | Citation Marker Offset: ['72'] | Citation Marker: 2004 | Citation Offset: ['72'] | Citation Text: <S sid ="72" ssid = "42">The DempsterShafer rule (Dempster, 1968), which combines the positive and negative pairwise decisions to score a partition, is used by Kehler (1997) and Bean and Riloff (2004) to identify the most probable NP partition.</S> | Reference Offset: ['49'] | Reference Text: <S sid ="49" ssid = "20">Using this heuristic, BABAR identifies existential definite NPs in the training corpus using our previous learning algorithm (Bean and Riloff, 1999) and resolves all occurrences of the same existential NP with each another.1 2.1.2 Syntactic Seeding BABAR also uses syntactic heuristics to identify anaphors and antecedents that can be easily resolved.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 14 | Reference Article: N04-1038.txt | Citing Article: P11-1082.txt | Citation Marker Offset: ['129'] | Citation Marker: 2004 | Citation Offset: ['129'] | Citation Text: <S sid ="129" ssid = "39">However, the use of related verbs is similar in spirit to Bean and Riloffâ€™s (2004) use of patterns for inducing contextual role knowledge, and the use of semantic roles is also discussed in Ponzetto and Strube (2006).</S> | Reference Offset: ['82'] | Reference Text: <S sid ="82" ssid = "20">For example, the passive voice pattern “&lt;subject&gt; were kidnapped” and the active voice pattern “kidnapped &lt;direct object&gt;” are merged into a single normalized pattern “kidnapped &lt;patient&gt;”.2 For the sake of sim plicity, we will refer to these normalized extraction patterns as caseframes.3 These caseframes can capture two types of contextual role information: (1) thematic roles corresponding to events (e.g, “&lt;agent&gt; kidnapped” or “kidnapped &lt;patient&gt;”), and (2) predicate-argument relations associated with both verbs and nouns (e.g., “kidnapped for &lt;np&gt;” or “vehicle with &lt;np&gt;”).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 15 | Reference Article: N04-1038.txt | Citing Article: P13-1121.txt | Citation Marker Offset: ['63'] | Citation Marker: 2004 | Citation Offset: ['63'] | Citation Text: <S sid ="63" ssid = "13">Caseframes do not consider the dependents of the semantic role approximations.The use of caseframes is well grounded in a va riety of NLP tasks relevant to summarization such as coreference resolution (Bean and Riloff, 2004)</S> | Reference Offset: ['187'] | Reference Text: <S sid ="187" ssid = "125">m(S) represents the belief that the correct hypothesis is included in S. The model assumes that evidence also arrives as a probability density function (pdf) over sets of hypotheses.6 Integrating new evidence into the existing model is therefore simply a matter of defining a function to merge pdfs, one representing the current belief system and one representing the beliefs of the new evidence.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 16 | Reference Article: N04-1038.txt | Citing Article: P13-2015.txt | Citation Marker Offset: ['46'] | Citation Marker: Bean and Riloff, 2004 | Citation Offset: ['46','47'] | Citation Text: <S sid ="46" ssid = "28">In addition, BABAR (Bean and Riloff, 2004) used contextual role knowledge for coreference resolution in the domains of terrorism and natural disasters.</S><S sid ="47" ssid = "29">But BABAR acquired and used lexical information to match the compatibility of contexts surrounding NPs, not the NPs themselves.</S> | Reference Offset: ['49'] | Reference Text: <S sid ="49" ssid = "20">Using this heuristic, BABAR identifies existential definite NPs in the training corpus using our previous learning algorithm (Bean and Riloff, 1999) and resolves all occurrences of the same existential NP with each another.1 2.1.2 Syntactic Seeding BABAR also uses syntactic heuristics to identify anaphors and antecedents that can be easily resolved.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 17 | Reference Article: N04-1038.txt | Citing Article: W05-0612.txt | Citation Marker Offset: ['33'] | Citation Marker: Bean and Riloff, 2004 | Citation Offset: ['33'] | Citation Text: <S sid ="33" ssid = "13">There are also approaches to anaphora resolution using unsupervised methods to extract useful information, such as gender and number (Ge et al., 1998), or contextual role-knowledge (Bean and Riloff, 2004).</S> | Reference Offset: ['241'] | Reference Text: <S sid ="241" ssid = "179">However their work did not consider other types of lexical expectations (e.g., PP arguments), semantic expectations, or context comparisons like our case- frame network.(Niyu et al., 1998) used unsupervised learning to ac quire gender, number, and animacy information from resolutions produced by a statistical pronoun resolver.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 18 | Reference Article: N04-1038.txt | Citing Article: W06-0106.txt | Citation Marker Offset: ['181'] | Citation Marker: 2004 | Citation Offset: ['181'] | Citation Text: <S sid ="181" ssid = "10">Bean and Riloff (2004) used information extraction patterns to identify contextual clues that would determine the compatibility between NPs.</S> | Reference Offset: ['49'] | Reference Text: <S sid ="49" ssid = "20">Using this heuristic, BABAR identifies existential definite NPs in the training corpus using our previous learning algorithm (Bean and Riloff, 1999) and resolves all occurrences of the same existential NP with each another.1 2.1.2 Syntactic Seeding BABAR also uses syntactic heuristics to identify anaphors and antecedents that can be easily resolved.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 19 | Reference Article: N04-1038.txt | Citing Article: W06-0206.txt | Citation Marker Offset: ['10'] | Citation Marker: Bean and Riloff, 2004 | Citation Offset: ['10'] | Citation Text: <S sid ="10" ssid = "10">It has shown promise in improving the performance of many tasks such as name tagging (Miller et al., 2004), semantic class extraction (Lin et al., 2003), chunking (Ando and Zhang, 2005), coreference resolution (Bean and Riloff, 2004)</S> | Reference Offset: ['6'] | Reference Text: <S sid ="6" ssid = "6">The problem of coreference resolution has received considerable attention, including theoretical discourse models (e.g., (Grosz et al., 1995; Grosz and Sidner, 1998)), syntactic algorithms (e.g., (Hobbs, 1978; Lappin and Le- ass, 1994)), and supervised machine learning systems (Aone and Bennett, 1995; McCarthy and Lehnert, 1995; Ng and Cardie, 2002; Soon et al., 2001).</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 20 | Reference Article: N04-1038.txt | Citing Article: W10-3909.txt | Citation Marker Offset: ['23'] | Citation Marker: 2004 | Citation Offset: ['22','23'] | Citation Text: <S sid ="22" ssid = "22">Methods for acquiring and using such knowledge are receiving increasing attention in 60 Proceedings of the Second Workshop on NLP Challenges in the Information Explosion Era (NLPIX 2010), pages 60â€“68, Beijing, August 2010 recent work on anaphora resolution.</S><S sid ="23" ssid = "23">Dagan and Itai (1990), Bean and Riloff (2004), Yang and Su (2007), and Ponzetto and Strube (2006) all explored this task.</S> | Reference Offset: ['49'] | Reference Text: <S sid ="49" ssid = "20">Using this heuristic, BABAR identifies existential definite NPs in the training corpus using our previous learning algorithm (Bean and Riloff, 1999) and resolves all occurrences of the same existential NP with each another.1 2.1.2 Syntactic Seeding BABAR also uses syntactic heuristics to identify anaphors and antecedents that can be easily resolved.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 21 | Reference Article: N04-1038.txt | Citing Article: W10-3909.txt | Citation Marker Offset: ['36'] | Citation Marker: 2004 | Citation Offset: ['36','37','38'] | Citation Text: <S sid ="36" ssid = "3">Bean and Riloff (2004) present a system, which uses contextual role knowledge to aid coreference resolution.</S><S sid ="37" ssid = "4">They used lexical and syntactic heuristics to identify high-confidence coreference relations and used them as training data for learning contextual role knowledge.</S><S sid ="38" ssid = "5">They got substantial gains on articles in two specific domains, terrorism and natural disasters.</S> | Reference Offset: ['49'] | Reference Text: <S sid ="49" ssid = "20">Using this heuristic, BABAR identifies existential definite NPs in the training corpus using our previous learning algorithm (Bean and Riloff, 1999) and resolves all occurrences of the same existential NP with each another.1 2.1.2 Syntactic Seeding BABAR also uses syntactic heuristics to identify anaphors and antecedents that can be easily resolved.</S> | Discourse Facet: BLANK | Annotator: Predictions

Citance Number: 22 | Reference Article: N04-1038.txt | Citing Article: W10-3909.txt | Citation Marker Offset: ['50'] | Citation Marker: 2004 | Citation Offset: ['50','51'] | Citation Text: <S sid ="50" ssid = "17">Bean and Riloff (2004) used high-precision hand-coded rules to identify coreferent mention pairs, which are then used to acquire role pairs that they refer to as Caseframe Network features.</S><S sid ="51" ssid = "18">They use these features to improve coreference resolution for two domain-specific corpora involving terrorism and natural disasters.</S> | Reference Offset: ['82'] | Reference Text: <S sid ="82" ssid = "20">For example, the passive voice pattern “&lt;subject&gt; were kidnapped” and the active voice pattern “kidnapped &lt;direct object&gt;” are merged into a single normalized pattern “kidnapped &lt;patient&gt;”.2 For the sake of sim plicity, we will refer to these normalized extraction patterns as caseframes.3 These caseframes can capture two types of contextual role information: (1) thematic roles corresponding to events (e.g, “&lt;agent&gt; kidnapped” or “kidnapped &lt;patient&gt;”), and (2) predicate-argument relations associated with both verbs and nouns (e.g., “kidnapped for &lt;np&gt;” or “vehicle with &lt;np&gt;”).</S> | Discourse Facet: BLANK | Annotator: Predictions

